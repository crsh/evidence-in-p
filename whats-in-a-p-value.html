<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Frederik Aust">
<meta name="author" content="Eric-Jan Wagenmakers">
<meta name="dcterms.date" content="2025-02-28">

<title>What’s in a p-value?</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="whats-in-a-p-value_files/libs/clipboard/clipboard.min.js"></script>
<script src="whats-in-a-p-value_files/libs/quarto-html/quarto.js"></script>
<script src="whats-in-a-p-value_files/libs/quarto-html/popper.min.js"></script>
<script src="whats-in-a-p-value_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="whats-in-a-p-value_files/libs/quarto-html/anchor.min.js"></script>
<link href="whats-in-a-p-value_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="whats-in-a-p-value_files/libs/quarto-html/quarto-syntax-highlighting-86daaaaad7353f9cc0c554efc1dd6d94.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="whats-in-a-p-value_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="whats-in-a-p-value_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="whats-in-a-p-value_files/libs/bootstrap/bootstrap-34bac7be86aa325ec92fc348cbeba8ad.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#p-as-conflict-or-surprise" id="toc-p-as-conflict-or-surprise" class="nav-link active" data-scroll-target="#p-as-conflict-or-surprise"><span class="header-section-number">0.1</span> <span class="math inline">\(p\)</span> as conflict or surprise</a></li>
  <li><a href="#quantifying-evidence" id="toc-quantifying-evidence" class="nav-link" data-scroll-target="#quantifying-evidence"><span class="header-section-number">0.2</span> Quantifying evidence</a></li>
  <li><a href="#sec-desirable-properties" id="toc-sec-desirable-properties" class="nav-link" data-scroll-target="#sec-desirable-properties"><span class="header-section-number">0.3</span> Desirable properties of the Bayes factor</a></li>
  <li><a href="#jeffreyss-approximate-bayes-factor-jab" id="toc-jeffreyss-approximate-bayes-factor-jab" class="nav-link" data-scroll-target="#jeffreyss-approximate-bayes-factor-jab"><span class="header-section-number">0.4</span> Jeffreys’s Approximate Bayes Factor (JAB)</a>
  <ul class="collapse">
  <li><a href="#assumptions" id="toc-assumptions" class="nav-link" data-scroll-target="#assumptions"><span class="header-section-number">0.4.1</span> Assumptions</a></li>
  </ul></li>
  <li><a href="#the-evidential-value-of-p" id="toc-the-evidential-value-of-p" class="nav-link" data-scroll-target="#the-evidential-value-of-p"><span class="header-section-number">1</span> The evidential value of <span class="math inline">\(p\)</span></a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">2</span> Conclusion</a></li>
  
  </ul>
</nav>
</div>
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">What’s in a <span class="math inline">\(p\)</span>-value?</h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Authors</div>
  <div class="quarto-title-meta-heading">Affiliations</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Frederik Aust <a href="mailto:frederik.aust@uni-koeln.de" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> <a href="https://orcid.org/0000-0003-4900-788X" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            University of Cologne
          </p>
        <p class="affiliation">
            University of Amsterdam
          </p>
      </div>
    <div class="quarto-title-meta-contents">
    <p class="author">Eric-Jan Wagenmakers <a href="https://orcid.org/0000-0003-1596-1034" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            University of Amsterdam
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">February 28, 2025</p>
    </div>
  </div>
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="block-title">Abstract</div>
    <strong>TODO</strong>
  </div>
</div>


</header>


<p>Null hypothesis significance testing is ubiquitous in psychological science and beyond. The key outcome of this statistical procedure is the <span class="math inline">\(p\)</span> value, which researchers routinely use to decide whether to reject the null hypothesis <span class="math inline">\(\mathcal{H}_0\)</span>. It is common to interpret <span class="math inline">\(p\)</span> values as a measure of statistical evidence or as the implied probability that <span class="math inline">\(\mathcal{H}_0\)</span> is true <span class="citation" data-cites="Gigerenzer2018 Cohen1994">(<a href="#ref-Gigerenzer2018" role="doc-biblioref">Gigerenzer 2018</a>; <a href="#ref-Cohen1994" role="doc-biblioref">Cohen 1994</a>)</span>. This is despite repeated efforts to explain that the <span class="math inline">\(p\)</span> value is <em>not</em> a measure of evidence [<strong>???</strong>, <span class="citation" data-cites="Hubbard2008">Hubbard and Lindsay (<a href="#ref-Hubbard2008" role="doc-biblioref">2008</a>)</span>; Royall, 1997; Goodman &amp; Royall, 1988]. In contrast, Bayesian model comparisons do yield a principled measure of relative evidence: the Bayes factor. However, unlike <span class="math inline">\(p\)</span> values, the Bayes factor is not routinely reported. Fortunately for the evidence-seeking reader, <span class="math inline">\(p\)</span> values can be monotonically related to the Bayes factor <span class="citation" data-cites="Berger1987">(<a href="#ref-Berger1987" role="doc-biblioref">Berger and Sellke 1987</a>)</span> and, as we will show, this relationship can be exploited to gauge the evidence implied by a reported <span class="math inline">\(p\)</span> value. All that is needed is the effective sample size <span class="citation" data-cites="Wagenmakers2022">(<a href="#ref-Wagenmakers2022" role="doc-biblioref">Wagenmakers 2022</a>)</span>. The resulting approximate Bayes factor is a useful tool for researchers, reviewers, and readers to interpret emprical results—even under conditions that threaten frequentist inference, most notably when the data may have been peaked at.</p>
<p>For those that unfamiliar with the debate, the upcoming section illustrate practical problems that arise when <span class="math inline">\(p\)</span> values are interpreted as measures of evidence. In the following two sections, we show that the Bayes factor avoids these problems because it quantifies evidence as the relative predictive accuracy of two competing hypotheses. We highlight two additional attractive properties of the Bayes factor: Identifying weak or inconclusive evidence and the independence of researchers’ sampling intentions. Although we have doen our best to make these section engaging, busy readers familiar with the Bayes factor may wish to skip them. We then get to the heart of our contribution: We show how the monotonic relationship between <span class="math inline">\(p\)</span> values and the Bayes factor can be exploited in a simple formula to approximate the Bayes factor. This approximation combines <span class="math inline">\(p\)</span> and effective sample size <span class="math inline">\(n_\text{eff}\)</span> and closely approximates the Bayes factor. We demonstrate the closeness of the approximation by reanalyzing two large datasets of published <span class="math inline">\(p\)</span> values for tests of mean comparisons and proportions. Finally, we discuss the implications of the approximation for the suggested evidential interpretations of <span class="math inline">\(p\)</span> values.</p>
<section id="p-as-conflict-or-surprise" class="level2" data-number="0.1">
<h2 data-number="0.1" class="anchored" data-anchor-id="p-as-conflict-or-surprise"><span class="header-section-number">0.1</span> <span class="math inline">\(p\)</span> as conflict or surprise</h2>
<p>To understand why <span class="math inline">\(p\)</span> values are not a measure of evidence, it may be useful to briefly review what they are. In the following, we will limit our discussion to one-sided <span class="math inline">\(p\)</span>-values for the sake of simplicity. The <span class="math inline">\(p\)</span> value is defined as the percentile of the observed test statistic <span class="math inline">\(t\)</span> in the distribution of all test statistics <span class="math inline">\(T\)</span> that could have been observed if the null hypothesis <span class="math inline">\(\mathcal{H}_0\)</span> were true,</p>
<p><span class="math display">\[
p = \text{Pr}(T \geq \text{abs}(t) \mid \mathcal{H}_0).
\]</span></p>
<p>In other words, the <span class="math inline">\(p\)</span> value is measure of conflict between the data and <span class="math inline">\(\mathcal{H}_0\)</span> and quantifies the information against <span class="math inline">\(\mathcal{H}_0\)</span>—smaller values indicating stronger conflict <span class="citation" data-cites="Perezgonzalez2015 Greenland2019">(<a href="#ref-Perezgonzalez2015" role="doc-biblioref">Perezgonzalez 2015</a>; <a href="#ref-Greenland2019" role="doc-biblioref">Greenland 2019</a>)</span>.</p>
<!-- You cannot load a coin! 10.1198/000313002605 -->
<p>This conflict between the data and <span class="math inline">\(\mathcal{H}_0\)</span> can be expressed on a different scale: the <span class="math inline">\(s\)</span> value, where <span class="math inline">\(s = -\log_2(p)\)</span> <span class="citation" data-cites="Rafi2020">(<a href="#ref-Rafi2020" role="doc-biblioref">Rafi and Greenland 2020</a>)</span>. The <span class="math inline">\(s\)</span> value can be thought of as a measure of <em>surprise</em> in units of bits (or Shannon-information). To intuit the meaning of a bit of information, indulge me in a game of chance: The rules are simple: I toss a coin; tails, you win; heads, I win. Let’s play. In the first round, I flip the coin and it comes up heads. I flip the coin a second time and, again, it comes up heads; the third and fourth time the coin also comes up heads. Take a moment to imagine your surprise; hold on to that feeling.</p>
<p>Entering this game of chance, you hopefully assumed that the coin is fair—who would try to cheat their readers. Based on this assumption every subsequent flip that comes up heads should increase your surprise about my run of good luck. The <span class="math inline">\(s\)</span> value quantifies this surprise: <span class="math inline">\(s = 2\)</span> corresponds to a streak of all heads from two tosses, <span class="math inline">\(s = 3\)</span> to a streak of all heads from three tosses, and so on. The surprise you felt after the fourth flip roughly corresponds to the surprise conveyed by <span class="math inline">\(p = .05 = .5^{4.32}\)</span> in an one-sided exact binomail test <span class="citation" data-cites="Greenland2019 Cole2020">(p.&nbsp;109, <a href="#ref-Greenland2019" role="doc-biblioref">Greenland 2019</a>; <a href="#ref-Cole2020" role="doc-biblioref">Cole, Edwards, and Greenland 2020</a>)</span>. I flip the coin one last time and, lo and behold, it comes up heads again.</p>
<p>Did I get lucky? Are you suspicious, yet? Am I using a flipping technique that biases the coin to come up heads? The <span class="math inline">\(p\)</span> value for this run of five heads drops to <span class="math inline">\(p = .031 = 0.5^5\)</span>; adopting an error rate of <span class="math inline">\(\alpha = .05\)</span>, which most scientific disciplines deem acceptable, the surprise, that is the conflict between data and <span class="math inline">\(\mathcal{H}_0:~\theta = .5\)</span> is strong enough to reject <span class="math inline">\(\mathcal{H}_0\)</span> and conclude foul play on my part. But I will protest: “This is preposterous! There is no evidence for such accusations. You are jumping to conclusions!” Well, what is the evidence? How strongly should my run of good luck change your belief that I tossed the coin fairly? Or, more formally, what is the posterior probability of <span class="math inline">\(\mathcal{H}_0\)</span> given the data <span class="math inline">\(\mathbf{y}\)</span>, <span class="math inline">\(\text{Pr}(\mathcal{H}_0 \mid \mathbf{y} = \text{{HHHHH}})\)</span>? To answer these question, we need to think about alternatives to <span class="math inline">\(\mathcal{H}_0\)</span>.</p>
<p>In the following section we attempt to convey an intuitve understanding of the Bayes factor and illustrate how this measure of evidence differs from the <span class="math inline">\(p\)</span> value. This and the next section may leave some readers wanting for a more in-depth treatment—we refer them to the annotated reading list provided by <span class="citation" data-cites="Etz2017 Allabadi2024 Morey2016">Etz et al. (<a href="#ref-Etz2017" role="doc-biblioref">2017</a>; also see <a href="#ref-Allabadi2024" role="doc-biblioref">Al-Labadi, Alzaatreh, and Evans 2024</a>; <a href="#ref-Morey2016" role="doc-biblioref">Morey, Romeijn, and Rouder 2016</a>)</span>.</p>
</section>
<section id="quantifying-evidence" class="level2 page-columns page-full" data-number="0.2">
<h2 data-number="0.2" class="anchored" data-anchor-id="quantifying-evidence"><span class="header-section-number">0.2</span> Quantifying evidence</h2>
<!-- - Researchers commonly interpret $p$-values as a measure of evidence (Nickerson, 2000, pp. 246-247; recently reviewed in <@Gigerenzer2018>)
    - Evidential interpretation is recommended in text books
        - Medical statistics: Bland
        - Statistics "proper": Wasserman
        - Other examples?
    - Fisher thought of $p$ as a measure of evidence''
        - "the observed _p_-value is taken as evidence against the null hypothesis, so that the smaller the _p_-value the stronger the evidence it provides ([Fisher, 1960](https://www.frontiersin.org/articles/10.3389/fpsyg.2015.00223/full#B18); [Spielman, 1978](https://www.frontiersin.org/articles/10.3389/fpsyg.2015.00223/full#B68))." (Perezgonzalez, 2015)
        - "Fisher's levels of significance: They do not need to be rigid (e.g., p-values such as 0.049 and 0.051 have about the same statistical significance around a convenient level of significance of 5%; Johnstone, 1987)." (Perezgonzalez, 2015; also see Cohen's "The world is round")
        - "In a Fisherian framework a _p_ value is interpreted as a continuous measure of compatibility between the observed data and the null hypothesis ([Greenland et al., 2016](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8114329/#bibr26-1745691620958012))." (Lakens, 2021)


- p-values are not a measure of evidence
    - They rely on counterfactual data and quantify the prior probability of the data given a null hypothesis
        - Fisher was vehemently against putting forward an alternative hypothesis (Hubbard, 2004; cited from Perezgonzalez, 2015).
    - Coherent use of p-values requires Neyman-Pearson testing approach
        - Specification of alternative hypothesis (smallest effect size of interest) and power
        - Control of error rates either via power considerations or ng NHST and equivalence testing
        - No assessment of evidence; decision procedure
            - "p-values [...] under this approach [...] have no evidential properties whatsoever (Frick, 1996; Gigerenzer, 2004)." (Perezgonzalez, 2015)
            - "If the observed result falls outside the critical region and the test has low power, conclude nothing. (Ideally, you would not carry out research with low power—Neyman, 1955)." (Perezgonzalez, 2015)
            - "[Neyman and Pearson (1933)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8114329/#bibr51-1745691620958012) were very clear that they did not intend to develop a method to inform us about the probability that our hypotheses are true, but that, “without hoping to know whether each separate hypothesis is true or false, we may search for rules to govern our behaviour with regard to them, in following which we insure that, in the long run of experience, we shall not be too often wrong” (p. 291)." (Lakens, 2021) -->
<!-- - Brief introduction to the Bayes factor
    - Relative prior predictive accuracy
    - Marginal likelihoods are difficult to calculate -->
<p>Quantifying <span class="math inline">\(\text{Pr}(\mathcal{H}_0)\)</span> requires that we distribute probabilities over a finite number of hypotheses <span class="math inline">\(\mathcal{H}_i\)</span>, such that <span class="math inline">\(\sum_i{\text{Pr}(\mathcal{H}_i)} = 1\)</span>. If no alternative to <span class="math inline">\(\mathcal{H}_0\)</span> exists, the posterior probability of <span class="math inline">\(\mathcal{H}_0\)</span> must be 1—regardless of the data. If there are alternatives but they are not specified, <span class="math inline">\(\text{Pr}(\mathcal{H}_0)\)</span> is undefined—we can only quantify the surprise, i.e.&nbsp;the conflict between the data and <span class="math inline">\(\mathcal{H}_0\)</span>. But it remains unclear how to translate this surprise into the probability that the coin was tossed fairly. We must specified alternative hypotheses to derive the posterior probability,</p>
<p><span class="math display">\[
\text{Pr}(\mathcal{H}_0 \mid \mathbf{y}) =  \text{Pr}(\mathcal{H}_0) \times \frac{\text{Pr}(\mathbf{y} \mid \mathcal{H}_0)}{\sum_i{\text{Pr}(\mathcal{H}_i) \times \text{Pr}(\mathbf{y} \mid \mathcal{H}_i)}}.
\]</span></p>
<p>So let’s think about alternatives to fair coin tossing. What’s the probability <span class="math inline">\(\theta\)</span> of coming up heads for coin tossing tricksters? Could I toss my coin to come up heads with a probability of <span class="math inline">\(\theta = 1\)</span> without youa noticing? The data seem to suggest that this is the most likely alternative wiht <span class="math inline">\(\hat\theta = 5/5 = 1\)</span>. This would be outrageous (but also impressive, no?), so let’s entertain this alternative hypothesis as <span class="math inline">\(\mathcal{H}_1\)</span>. Maybe I am a less skilled or more subtle trickster, flipping my coin to come up heads with a probability of <span class="math inline">\(\theta = .60\)</span>, <span class="math inline">\(\theta = .65\)</span>, or <span class="math inline">\(\theta = .70\)</span>? None of these exact probabilites seems to deserve special consideration. All are plausible, some more than others; so we will specify a general alternative hypothesis and assign <span class="math inline">\(\theta\)</span> a prior distribution constraining <span class="math inline">\(\theta &gt; .5\)</span>, <span class="math inline">\(\mathcal{H}_2:~2\theta-1 \sim \mathcal{B}(a = 2, b = 3)\)</span>, see <a href="#fig-coin-hypotheses" class="quarto-xref">Figure&nbsp;1</a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-coin-hypotheses" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-coin-hypotheses-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="whats-in-a-p-value_files/figure-html/fig-coin-hypotheses-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-coin-hypotheses-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Prior probability distributions for the probability of heads <span class="math inline">\(\theta\)</span> for the toss of a coin. The orange arrow represents the point hypothesis <span class="math inline">\(\mathcal{H}_0\)</span> that the coin is fair, the purple arrow represents the point hypothesis <span class="math inline">\(\mathcal{H}_1\)</span> that the coin always comes up heads, and the red curve is the continuous hypothesis <span class="math inline">\(\mathcal{H}_2\)</span> that the coin is loaded to come up heads but the probability of heads is unknown. The dashed line represents the posterior distribution of <span class="math inline">\(\theta\)</span> given <span class="math inline">\(\mathcal{H}_2\)</span> and the data <span class="math inline">\(\mathbf{y} = \{HHHHH\}\)</span>.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Deriving the posterior probability of <span class="math inline">\(\mathcal{H}_0\)</span> directly is conceptually inconvenient. Reasonable people will disagree what all relevant alternatives are and how likely they are a priori. It is more convenient to think about the odds of pairs of hypotheses and the relative evidence in the data, i.e.&nbsp;the Bayes factor (BF) <span class="math inline">\(\text{BF}_{01}\)</span>:</p>
<p><span class="math display">\[
\underbrace{ \frac{p(\mathcal{H}_0  \mid \mathbf{y})}{p(\mathcal{H}_1  \mid \mathbf{y})}}_{\substack{\text{Posterior beliefs}\\ \text{about hypotheses}} } \,\, =
\underbrace{ \frac{p(\mathcal{H}_0)}{p(\mathcal{H}_1)}}_{\substack{\text{Prior beliefs}\\ \text{about hypotheses}} }
\times \,\,\,\,\,
\underbrace{ \frac{p(\mathbf{y} \mid \mathcal{H}_0)}{p(\mathbf{y} \mid  \mathcal{H}_1)}}_{\substack{\text{Bayes factor BF}_{01}\\(\text{relative evidence}) } }.
\]</span></p>
<p>On the odds scale, we can limit our considerations to two relevnt hypotheses and it allows us to separate the prior beliefs from the evidence in the data. Now it becomes clear that according to Bayes theorem, evidence is defined as the relative predictive accuracy of two hypotheses. The evidence quantifies how much better one hypothesis predicts the data than another, or with under which hypothesis the data are less surprising.</p>
<p>So, what’s the evidence that I cheated you? As noted above, a run of five heads corresponds to a <span class="math inline">\(p = .031 = 0.5^5\)</span> and <span class="math inline">\(s = 5\)</span> assuming <span class="math inline">\(\mathcal{H}_0\)</span> is true and <span class="math inline">\(\theta = .5\)</span>. Conveniently, I constructed this example such that <span class="math inline">\(\Pr(\mathbf{y} \mid \mathcal{H}_i) = \theta^5 = p\)</span>—this is usually not the case. This means that if <span class="math inline">\(\mathcal{H}_1\)</span> is true and <span class="math inline">\(\theta = 1\)</span>, <span class="math inline">\(\Pr(\mathbf{y} \mid \mathcal{H}_1) = 1\)</span>. Hence, assuming that if I cheat it is literally <em>impossible</em> for the coin to come up tails, the data are strong evidence that I cheated you, <span class="math inline">\(\text{BF}_{10} = 1/p = 1/.031 = 32\)</span>, <a href="#tbl-evidence-categories" class="quarto-xref">Table&nbsp;1</a>.</p>
<p>Attentive readers may now point out that, counter to our initial claims, <span class="math inline">\(p = 1/\text{BF}_{10} = \text{BF}_{01}\)</span> <em>is</em> a measure of evidence against <span class="math inline">\(\mathcal{H}_0\)</span>—if we assume that <span class="math inline">\(\mathcal{H}_1\)</span> is the relavant alternative hypothesis. But this is a unlikely coincidence and immediately problems loom large. Most obviously, <span class="math inline">\(\mathcal{H}_1\)</span> is an extreme and probably irrelevant alternative hypothesis. I feel honored if you think otherwise, but I’m just not a skilled enough trickster. But this evidential interpretation of <span class="math inline">\(p\)</span> sufferes from a more serious problem. Let’s briefly continue to entertain <span class="math inline">\(\mathcal{H}_1\)</span> and imagine the outcome of my fifth flip had been tails—not heads. Now <span class="math inline">\(\Pr(\mathbf{y} \mid \mathcal{H}_0) = p = .187\)</span> and <span class="math inline">\(s = 2.42\)</span>, so we should be less surprised—roughly equivalent to the surprise of 2 heads out of 2 tosses. But when we take our alternative hypothesis into account, we see a stark difference between <span class="math inline">\(p\)</span> and the Bayes factor: <span class="math inline">\(\Pr(\mathbf{y} \mid \mathcal{H}_1) = 0\)</span> and hence <span class="math inline">\(\text{BF}_{01} = .187/0 = \infty\)</span>. Take a moment to reflect what this means: The <span class="math inline">\(p\)</span> value proclaims some conflict between the data and <span class="math inline">\(\mathcal{H}_0\)</span>, but the real story here is that <span class="math inline">\(\mathcal{H}_1\)</span> has been conclusively ruled out. The evidential interpretation of <span class="math inline">\(p\)</span> could hardly be more misleading.</p>
<!-- We cannot corroborate!
But this is not a relative measure and the alternative hypothesis to the fair coin remains unspecified and thereby implicit.
This measure is not consistent in that it will not select a true H_0 in an infinitely large sample because the the random variable $P$ is uniformly distributed on $[0, 1]$ under $\mathcal{H}_0$.
It can only quantify information at odds with $\mathcal{H}_0$. -->
<p>The evidential interpretation of <span class="math inline">\(p\)</span> misleads us because <span class="math inline">\(p\)</span> does not take any alternative hypotheses into account. Consider another possible outcome of my coin flips to see appreciate that <span class="math inline">\(p\)</span> can never corroborate <span class="math inline">\(\mathcal{H}_0\)</span>. Imagine my coin had come up tails—not heads—five times in a row. Now <span class="math inline">\(\Pr(\mathbf{y} \mid \mathcal{H}_0) = p = 1\)</span> and <span class="math inline">\(s = 0\)</span>. Again, appreciate what this means. The data could not be more compatible with <span class="math inline">\(\mathcal{H}_0\)</span> (remember, we assume I am a self-serving cheater and <span class="math inline">\(\theta &gt; .5\)</span>, i.e.&nbsp;the test is one-tailed). The <span class="math inline">\(p\)</span> value can only indicates that we should not be surprised. In fact, as the <span class="math inline">\(s\)</span> value highlights, it is like having observed no data at all!</p>
<p>But on to the burning question: What is the evidence I cheated assuming that my skills to bias the coin are more modest, <span class="math inline">\(\mathcal{H}_2\)</span>. The data provide moderate evidence that my flipping is biased to come up heads, <span class="math inline">\(\text{BF}_{02} = 0.5^5 / 0.205 = 0.153\)</span>. The evidence is weaker than for <span class="math inline">\(\mathcal{H}_1\)</span> because the predictions of <span class="math inline">\(\mathcal{H}_2\)</span> are less extreme and more similar to those of <span class="math inline">\(\mathcal{H}_0\)</span>. Whether you think this evidence is enough to accuse me of foul play depends on your prior beliefs about <span class="math inline">\(\mathcal{H}_0\)</span> and <span class="math inline">\(\mathcal{H}_2\)</span> of course. I have a strong prior belief in my own honesty—there is considerable empricial evidence for my unbiased coin flipping technique <span class="citation" data-cites="Bartos2024">(Table 1 in <a href="#ref-Bartos2024" role="doc-biblioref">Bartoš et al. 2024</a>)</span>! But I won’t hold it against you if you suspect otherwise. Before you convict me, however, remember that your prior probability may be tainted by the fact that we’ve already seen the data. Did you suspect I would cheat you when opening this article? Unless you are a paragon of virtue or a perfectly rational robot capable of compartmentalizing information, it’s wise to approach this task conservatively. Pretending we haven’t seen what we’ve seen is about as easy as un-ringing a bell.</p>
<p>We will discuss how to derive an approximate Bayes factor from <span class="math inline">\(p\)</span>, shortly, but let’s first examine the Bayes factor if we again imagine my coin had come up tails—not heads—five times in a row. As we have seen <span class="math inline">\(p = 1\)</span> and <span class="math inline">\(s = 0\)</span>—no surprise, no information. The Bayes factor, on the other hand, indicates strong evidence in favor of the coin being fair, <span class="math inline">\(\text{BF}_{02} = 0.5^5 / 0.005 = 192\)</span>. A judge who relies on <span class="math inline">\(p\)</span> as a measure of evidence risks ignoring evidence to the contrary<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>; a judge who considers the Bayes factor stands a chance to uphold the principles of Justitia. Or in the words of <span class="citation" data-cites="Jeffreys1961">(<a href="#ref-Jeffreys1961" role="doc-biblioref"><strong>Jeffreys1961?</strong></a>)</span>,</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;Those, uninterested in evidence, may use <span class="math inline">\(p\)</span> in a Neyman-Pearson decision procedure to reject <span class="math inline">\(\mathcal{H}_0\)</span> when <span class="math inline">\(p \leq \alpha\)</span> and will be wrong at a rate of <span class="math inline">\(\alpha\)</span> in the long run. Such a decision procedure can reject <span class="math inline">\(\mathcal{H}_1\)</span> on the basis of <span class="math inline">\(p &gt; \alpha\)</span> only if the study and decision procedure has a known and low enough long-run risk of such decisions being incorrect, <span class="math inline">\(\beta\)</span> <span class="citation" data-cites="Greenland2019">(<a href="#ref-Greenland2019" role="doc-biblioref">Greenland 2019</a>)</span>. Yet none of these additional steps warrant an evidential interpretation of <span class="math inline">\(p\)</span>.</p></div></div><blockquote class="blockquote">
<p>The most serious drawback […] is the deliberate omission to give any meaning to the probability of a hypothesis. All that they can do is to set up a hypothesis and give arbitrary rules for rejecting it in certain circumstances. They do not say what hypothesis should replace it in the event of rejection […] It is merely something set up like a coconut to stand until it is hit […] (p.&nbsp;377)</p>
</blockquote>
<!-- NP-Testing:
$p$ values are defined in relation to a theoretical distribution of counterfactual data $T$ that could have been observed under $\mathcal{H}_0$.
Therefore $p$ is a theoretical long-run probability conditional on $\mathcal{H}_0$ being true.

> In the decision-theoretical (Neyman– Pearsonian) definition, the observed p is often defined as the smallest α level (testing cutoff) that would allow rejection in an α-level decision rule (Neyman–Pearson hypothesis test) which rejects H when p ≤ α (e.g., Lehmann 1986). 

In NP, $p$ is considered a realization of a random variable $P$ resulting from counterfactually repeated experiments.
If $\mathcal{H}_0$ were true, $P$ is uniformly distributed on $[0, 1]$ and the decision to reject $\mathcal{H}_0$ when $p \leq \alpha$ is associated the long-run risk $\alpha$ of being incorrect. -->
</section>
<section id="sec-desirable-properties" class="level2 page-columns page-full" data-number="0.3">
<h2 data-number="0.3" class="anchored" data-anchor-id="sec-desirable-properties"><span class="header-section-number">0.3</span> Desirable properties of the Bayes factor</h2>
<p>As noted above, psychological researchers commonly interpret <span class="math inline">\(p\)</span> values as a measure of statistical evidence or as the implied probability that a statistical hypothesis is true <span class="citation" data-cites="Gigerenzer2018 Cohen1994">(<a href="#ref-Gigerenzer2018" role="doc-biblioref">Gigerenzer 2018</a>; <a href="#ref-Cohen1994" role="doc-biblioref">Cohen 1994</a>)</span>. For this reason alone the Bayes factor is a desirable alternative to the <span class="math inline">\(p\)</span> value. But the Bayes factor has other desirable properties that make it a useful tool for researchers, reviewers, and readers of the scientific literature. Consider the following two properties: The Bayes factor clearly indicates when the data provide weak or inconclusive evidence, and is independet of researchers’ sampling intentions.</p>
<p>As demonstrated, the Bayes factor is a contiuous measure of relative evidence. It can indicate whether the data support <span class="math inline">\(\mathcal{H}_1\)</span> or <span class="math inline">\(\mathcal{H}_0\)</span>. However sometimes the data provide little or no evidence either way. Recognizing inconclusive results is crucial; <!-- data provide weak or inconclusive evidence. --> it should prompt researchers to avoid strong claims, collect more data, design a more informative study, or to consider other hypotheses. The Bayes factor clearly indicates when this is the case: When the data are equally likely under <span class="math inline">\(\mathcal{H}_0\)</span> and <span class="math inline">\(\mathcal{H}_1\)</span>, the Bayes factor is 1. In contrast, a large, non-significant p-value from null hypothesis significance testing (NHST) is often difficult to interpret. It indicates that the data are relatively unsurprising under <span class="math inline">\(\mathcal{H}_0\)</span>—the hypothesis should not be rejected. But on its own <span class="math inline">\(p\)</span> can never tell us if should be accepted <span class="math inline">\(\mathcal{H}_0\)</span> is true<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. To make this determination, researchers should additionally must consider the <span class="math inline">\(p\)</span> for an interval nullhypothesis, such as <span class="math inline">\(H_0:~.4 \geq \theta \leq .6\)</span> [equivalence test; pp.&nbsp;292–302, <span class="citation" data-cites="Lakens2022">Lakens (<a href="#ref-Lakens2022" role="doc-biblioref">2022</a>)</span>]<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. If both <span class="math inline">\(p &gt; \alpha\)</span>, the data are insufficiently surprising under both hypotheses to warrant rejecting either one—the results are inconclusive. It is ecouraging that reporting Bayes factors or equivalence tests is becoming more common, but the majority of papers still report neither. It can therefore be difficult for reviewers and readers to evaluate which claims receive support from the data and which claims mostly reflect researchers’ prior convictions. A method to approximate Bayes factor from NHST-<span class="math inline">\(p\)</span> values should be a useful for anyone evaluating claims from empirical research, including reviewers and readers alike.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;Those, uninterested in evidence, may use <span class="math inline">\(p\)</span> in a Neyman-Pearson decision procedure to reject <span class="math inline">\(\mathcal{H}_0\)</span> when <span class="math inline">\(p \leq \alpha\)</span> and will be wrong at a rate of <span class="math inline">\(\alpha\)</span> in the long run. Such a decision procedure can reject <span class="math inline">\(\mathcal{H}_1\)</span> on the basis of <span class="math inline">\(p &gt; \alpha\)</span> only if the study and decision procedure has a known and low enough long-run risk of such decisions being incorrect, <span class="math inline">\(\beta\)</span> <span class="citation" data-cites="Greenland2019">(<a href="#ref-Greenland2019" role="doc-biblioref">Greenland 2019</a>)</span>. Yet none of these additional steps warrant an evidential interpretation of <span class="math inline">\(p\)</span>.</p></div><div id="fn3"><p><sup>3</sup>&nbsp;In a Neyman-Person testing procedure, a non-significant <span class="math inline">\(p\)</span> value may prompt the acceptance of <span class="math inline">\(\mathcal{H}_0\)</span>, only if the design of the study set the probability of falsely accepting <span class="math inline">\(\beta\)</span> at a level that is deemed acceptable. More often than not <span class="math inline">\(\beta\)</span> is unknown even for key hypothesis tests to reviewers and readers—or the researchers themselves.</p></div><div id="fn4"><p><sup>4</sup>&nbsp;The Poisson distribution is probably a bad model for the number of coin flips in a fixed amount of time, but it is a simple and illustrative example.</p></div><div id="fn5"><p><sup>5</sup>&nbsp;In the absence of a well defined sampling distribution, the <span class="math inline">\(p\)</span> value can be obtained by simulating the relevant statistic—the relative frequency of heads—-under <span class="math inline">\(\mathcal{H}_0\)</span> and calculating the percentile of the observed outcome. Here, we first sample a sample size from a Poisson distribution and then simulate the number of heads in this sample size from a binomial distribution.</p></div></div><p>To appreciate the relevance of reasearchers’ sampling intentions, let us once more return to our game of chance. You accused me of cheating after a run of 5 heads as I explained that this corresponds to <span class="math inline">\(p = 0.5^5 = .031\)</span>. But maybe <em>I</em> was the one jumping to conclusions afterall: I assumed a <span class="math inline">\(\mathcal{H}_0\)</span> that treats the number of heads as a binomial random variable <span class="math inline">\(K \sim \text{Bin}(n = 5, \theta = .5)\)</span>. Notice here that this <span class="math inline">\(\mathcal{H}_0\)</span> actually has two parameters—<span class="math inline">\(n\)</span> and <span class="math inline">\(\theta\)</span>—and that both parameters are assumed to be fix to specific values. I think we agree on the assumption that <span class="math inline">\(\theta = .5\)</span>; it is a statement about my character that you want to test. That <span class="math inline">\(n = 5\)</span>, on the other hand, is an assumption I made about the data collection procedure: Every dataset you could have observed consists of exactly <span class="math inline">\(n = 5\)</span> coin flips. In other words, <span class="math inline">\(p = 0.5^5 = .031\)</span> only if one of us had decided that we would see exactly <span class="math inline">\(n = 5\)</span> flips. In fact, my intention was to flip my coin until my thumb hurts, but at least 10.000 times. You surely are a busy reader, so maybe you figured that you could spare no more than 30 seconds. In this case <span class="math inline">\(n\)</span> is a random variable <span class="citation" data-cites="Kruschke2014">(Chapter 11, <a href="#ref-Kruschke2014" role="doc-biblioref">Kruschke 2014</a>)</span>. I can toss coins at a rate of <span class="math inline">\(\lambda = 19\)</span> tosses per minute <span class="citation" data-cites="Bartos2024">(<a href="#ref-Bartos2024" role="doc-biblioref">Bartoš et al. 2024</a>)</span>, but in a tutorial setting it would be closer to <span class="math inline">\(\lambda = 10\)</span>. So unbeknowst to me, the data were collected not with the intention that <span class="math inline">\(n = 5\)</span>, but <span class="math inline">\(N \sim \text{Pois}(\lambda = 5)\)</span><a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>. In this case, the probabilitiy of observing a run of all heads in our game is <span class="math inline">\(p = .075\)</span><a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>. But, here I go again: I’m assuming. Maybe the time you are willing to spare is itself a random variable. Or maybe your sampling intentions change in light of your observations: After seeing 4 out of 4 heads you decided to keep watching to see if my run of good luck continues. I can never know.</p>
<p>We hope that this example illustrates how problematic it is for a measure of evidence to depend on researchers’ sampling intentions. <span class="math inline">\(p\)</span> is defined in reference to an imagined set of infinite replications of the data collection precedure. Hence, this procedure must be known to calculate <span class="math inline">\(p\)</span>. Most NHST procdures assume fixed-<span class="math inline">\(n\)</span> designs, but researchers sampling intentions are often more complicated, sometimes subject to change, and are often unclear to reviewers and readers. The Bayes factor quantifies the relative evidence only in the data at hand and, therefore, requires no assumptions about researchers’ intentions (<em>likelihood principle</em>, <strong>???</strong>). Bayes factors are readily interpretable even when researchers stopped collecting data because <span class="math inline">\(p &lt; \alpha\)</span>—a practice well known to inflate the risk of incorrectly rejecting <span class="math inline">\(\mathcal{H}_0\)</span>. Hence, we believe a method to approximate the Bayes factor from NHST-<span class="math inline">\(p\)</span> values should be useful to everyone involved: researchers, reviewers and readers of the scientific literature.</p>
<!-- - Judging from the common evidential interpretation, researchers seem to want a measure of evidence
-  Principled/Ideological reasons to prefer evidence
    - Interested in evidence rather than decision procedure
        - "[Rozeboom (1960)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8114329/#bibr59-1745691620958012) criticized the use of NHST because “the primary aim of a scientific experiment is not to precipitate decisions, but to make an appropriate adjustment in the degree to which one accepts, or believes, the hypothesis or hypotheses being tested.” (p. 420). If this is your philosophy, then a _p_ value is unlikely to provide the answer you are looking for, and you might prefer to draw nondichotomous inferences using a likelihood ratio, Bayes factor, or a Fisherian interpretation of _p_ values." (Lakens, 2021)
    - Derive probability that a hypothesis is true
      - " As seen above, Berger and his colleagues had already shown the p value to be a poor gauge of evidence in a Bayesian context. They now wanted to determine if p values are useful measures of evidence against H0 when considered from a Neyman–Pearsonian perspective. Accordingly, Sellke et al. (2001) devised a method for ‘calibrating’ p values so that they can be interpreted as Neyman–Pearson frequentist error probabilities. The end result of this calibration is as follows: α(p) = (1 + [– e p log(p)]−1)−1. Consequently, p = .05 translates into frequentist error probability α (.05) = .289 in rejecting H0—a result suggesting no evidence against H0. Even α (.01) = .111. These findings convey in a non-Bayesian manner the severe problems involved in using p values as credible measures of evidence against the null hypothesis." (Hubbard & Lindsay, 2008)
- Practical reasons to prefer evidence
    - A measure of relative evidence helps to distinguish between evidence of absence and absence of evidence
        - Without additional information a non-significant p-value is difficult to interpret
            - Power: very often not available because power differs for every test in a paper and power is typically only reported for one test, hopefully focal one
            - Equivalence tests: May not be readily available and concept of practical equivalence is difficult to apply (Check out Laken's work on this)
                - Lakens, D. (2022). Improving Your Statistical Inferences. Retrieved from https://lakens.github.io/statistical_inferences/. https://doi.org/@Lakens2022 (pp. 292--302)
        - Bayesian evidence follows the likelihood principle and does not condition on the sampling procedure, i.e. is interpretable when the data have been peaked at
            - Tool for reviewers/readers -->
<!-- ### Challenges with evidence

- Readers/Reviewers
    - Data may not be available for reanalysis
    - Reanalyses are time consuming and cumbersome -->
</section>
<section id="jeffreyss-approximate-bayes-factor-jab" class="level2 page-columns page-full" data-number="0.4">
<h2 data-number="0.4" class="anchored" data-anchor-id="jeffreyss-approximate-bayes-factor-jab"><span class="header-section-number">0.4</span> Jeffreys’s Approximate Bayes Factor (JAB)</h2>
<p>In the previous sections we discussed the conceptual and practical problems that arise when interpreting <span class="math inline">\(p\)</span> values as a measure of evidence. We introduced the Bayes factor as an alternative, showed that it overcomes the problems of the <span class="math inline">\(p\)</span> value, and highlighted some of its desirable properties. <!-- As noted above, $p$ values continue to be ubiquitously reported in psychological research. --> Against this backdrop, it may be unexpected that the surprise quantified by the fixed-<span class="math inline">\(n\)</span>-<span class="math inline">\(p\)</span> value can be used to calculate a remarkably good approximation to the Bayes factors. We briefly explain and illustrate this approximation, known as jeffreys’s Approximate Bayes factor (JAB) and then explore it’s implications for an evidential interpretation of the <span class="math inline">\(p\)</span> value.</p>
<!-- - There is a monotonic relationship between $p$ and $p(H_0 | D)$ (Berger & Selke, 1987)
    - $p$, however, is typically smaller than $p(H_0 | D)$ (but this depends on the sample size, as we will show!) (Berger & Selke, 1987; Lindley, 1993, p. 25)
- We will show that this monotonic relationship can exploited and $p$-values be used in a surprisingly good approximation of Bayesian evidence -->
<p><span class="citation" data-cites="Berger1987">Berger and Sellke (<a href="#ref-Berger1987" role="doc-biblioref">1987</a>)</span> showed that there is a monotonic relationship between <span class="math inline">\(p\)</span> and the Bayes factor or <span class="math inline">\(\text{Pr}(\mathcal{H}_0 \mid \mathbf{y})\)</span>. For a given sample size, larger effects yield smaller <span class="math inline">\(p\)</span> values and stronger evidence against <span class="math inline">\(\mathcal{H}_0\)</span>. <span class="citation" data-cites="Marsman2016">Marsman and Wagenmakers (<a href="#ref-Marsman2016" role="doc-biblioref">2016</a>)</span> show that, for location parameters <span class="math inline">\(\mu\)</span> in the exponential family (e.g., a normal distribution) and a given sample size <span class="math inline">\(n\)</span>, the logarithms of the one-sided <span class="math inline">\(p\)</span> value and the Bayes factor are approximately linearly related. We illustrate this relationship in <a href="#fig-jab-jzs" class="quarto-xref">Figure&nbsp;2</a> for the published <span class="math inline">\(t\)</span>-test collected by Aczel et al.&nbsp;(2018) and Wetzels et al.&nbsp;(2011; previously reanalyzed by Rouder et al., 2012). Triangles show the linear relationsip between the one-sided <span class="math inline">\(p\)</span> value and the commonly used JZS-Bayes factors (<strong>???</strong>) on logarithmic scales. Note that the these <span class="math inline">\(t\)</span>-test results are based on studies with varying sample size <span class="math inline">\(n\)</span>. Two things are worth noting: (1) The logarithm of the one-sided <span class="math inline">\(p\)</span> values is substantially smaller than the Bayes factor—as a measure of evidence, it overstates the evidence against <span class="math inline">\(\mathcal{H}_0\)</span>. <!-- In fact, the one-sided $p$ value always exceeds the theoretical upper bound on the Bayes factor, as indicated by the dashed grey line---the so-called Vovk-Sellke bound (**???**). --> (2) There is systematic variability around the best fitting line: <span class="math inline">\(p\)</span> values for large samples fall above the line, while <span class="math inline">\(p\)</span> values for small samples fall below the line. Hence, despite being linear related to the Bayes factor, the one-sided <span class="math inline">\(p\)</span> value itself is a relatively poor approximation. An improved approximation must reduce the bias against <span class="math inline">\(\mathcal{H}_0\)</span> and take the sample size into account.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-jab-jzs" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-jab-jzs-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="whats-in-a-p-value_files/figure-html/fig-jab-jzs-1.png" class="img-fluid figure-img" width="739">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-jab-jzs-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Linear relationships between analytic JZS-Bayes factors for prior scale <span class="math inline">\(r = 1\)</span> and the corresponding JAB for 704 <span class="math inline">\(t\)</span>-test results collected by Aczel et al.&nbsp;(2018) and Wetzels et al.&nbsp;(2011). Triangles represent the logarithm of the one-sided <span class="math inline">\(p\)</span>-values, circles represent the logarithm of <span class="math inline">\(\text{JAB}_{01}\)</span>. The color of points indicates the effective sample size. The thick solid black line shows the estimated linear relationship between the one-sided <span class="math inline">\(p\)</span> values and the JZS-Bayes factor.
</figcaption>
</figure>
</div>
</div>
</div>
<p><span class="citation" data-cites="Wagenmakers2022">Wagenmakers (<a href="#ref-Wagenmakers2022" role="doc-biblioref">2022</a>)</span> recently highlighted that <span class="math inline">\(p\)</span> values of single-parameter Wald tests are directly related to Jeffreys’s approximate Bayes factor (JAB; Jeffreys, 1936). Jeffreys showed that an approximate Bayes factor can be obtained from the Wald statistic</p>
<p><span class="math display">\[
W = \bigg [ \frac{\hat \theta - \theta_0}{\text{SE}(\hat \theta)} \bigg ]^2
\]</span></p>
<p>for a test-relevant parameter <span class="math inline">\(\theta\)</span> and the null value <span class="math inline">\(\theta_0\)</span> as</p>
<p><span id="eq-jab"><span class="math display">\[
\text{JAB}_{01} = A \; \sqrt{n_\text{eff}} \; \exp(-0.5 W),
\tag{1}\]</span></span></p>
<p>where <span class="math inline">\(\sqrt{n_\text{eff}}\)</span> is the <em>effective sample size</em> that scales the standard error (see <a href="#sec-appendix-n-eff" class="quarto-xref">Section&nbsp;3.1</a>) and <span class="math inline">\(A = [\sqrt{2 \pi}~\sigma~g(\hat \theta | \mathcal{H}_1)]^{-1}\)</span> depends on the prior distribution <span class="math inline">\(g()\)</span> evaluated at the maximum likelihood estimate of the test-relevant parameter <span class="math inline">\(\hat \theta\)</span> and residual standard deviation <span class="math inline">\(\sigma\)</span>. JAB relates to two-sided <span class="math inline">\(p\)</span>-values through the quantile function <span class="math inline">\(Q\)</span> of the asymptotic sampling distributions of the corresponding Wald test statistic—the <span class="math inline">\(\chi^2(\mathrm{df} = 1)\)</span>-distribution or the standard normal distribution <span class="math inline">\(\mathcal{N(\mu = 0, \sigma = 1)}\)</span>,</p>
<p><span id="eq-w-p"><span class="math display">\[
\begin{aligned}
W &amp; = \phantom{[} Q_{\chi^2(1)}(1-p) \phantom{]^2} &amp; \text{for } \chi^2\text{-tests and} \\
  &amp; = [Q_{\mathcal{N(0,1)}}(p/2)]^2 &amp; \text{for } z\text{-tests.}
\end{aligned}
\tag{2}\]</span></span></p>
<p>The latter is, in words, the square of the probit-transformed one-sided <span class="math inline">\(p\)</span>-value. So, JAB can be understood as a transformation of the Wald <span class="math inline">\(p\)</span>-value using sample size that yields a principled measure of evidence. In this way, JAB addresses the two short-comings of the one-sided <span class="math inline">\(p\)</span> value discussed above: It removes the bias against the null hypothesis and takes the sample size into account. The circles in <a href="#fig-jab-jzs" class="quarto-xref">Figure&nbsp;2</a> illustrate that the analytic JZS-Bayes factor with prior scale <span class="math inline">\(r = \sqrt{2}/2\)</span> is approximated well by corresponding JAB<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>. Only when the effective sample size is very small does JAB deviate noticably from the JZS-Bayes factor. These deviations, while noticable, are small enough to be inconsequential. In contrast to the one-sided <span class="math inline">\(p\)</span> value, JAB largely accounts for differences in evidence related to sample size. <!-- Note that JAB indicates stronger evidence against $\mathcal{H}_0$ than the JZS-Bayes factor---the points are shifted to the left of the dashed line.
The reason for this is that the two Bayes factors follow from different prior distributions.
An exact correspondence between JAB assuming a unit-information prior and the JZS-Bayes factor is not expected. --> <!-- In @sec-appendix-bic, we show that JAB closely correpsonds to the BIC-approximation to the Bayes factor. --></p>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;Because here the <span class="math inline">\(p\)</span>-values are from a <span class="math inline">\(t\)</span>- rather than a Wald test, we use the analytic expression for the log likelihood ratio rather than an approximation based on <span class="math inline">\(p\)</span> itself, <a href="#sec-appendix-llr" class="quarto-xref">Section&nbsp;3.2</a>. With an approximate likelihood ratio based on the <span class="math inline">\(p\)</span>-value (<a href="#eq-w-p" class="quarto-xref">Equation&nbsp;2</a>), JAB understates the evidence against <span class="math inline">\(\mathcal{H}_0\)</span> when effects are large and the effective sample size is small. Note, however, that in the data used here the bias exceedes a factor of 3 only in very small samples, <a href="#sec-appendix-llr" class="quarto-xref">Section&nbsp;3.2</a>. We believe, in most situations, the <span class="math inline">\(p\)</span>-based JAB is a fair approximation to the JZS-Bayes factor for <span class="math inline">\(t\)</span>-tests.</p></div></div><p>As noted above, the linear relationship between one-sided <span class="math inline">\(p\)</span> values and the Bayes factor shown in <a href="#fig-jab-jzs" class="quarto-xref">Figure&nbsp;2</a> only holds for tests of location parameters <span class="math inline">\(\mu\)</span> in the exponential family (e.g., assuming normally distributed errors). When the tested hypothesis is of a different kind, the close relationship between <span class="math inline">\(p\)</span> and the Bayes factor can break down. Consider the example of comparing two independent proportions <span class="math inline">\(\theta_1\)</span> and <span class="math inline">\(\theta_2\)</span>, where <span class="math inline">\(\mathcal{H}_0: \theta_1 = \theta_2\)</span>. When the number of observations is large and the probabilities not too exreme, we can test this hypothesis using a Pearson’s <span class="math inline">\(\chi^2\)</span>-test applied to the 2 <span class="math inline">\(\times\)</span> 2-contingency table. Another option is to reformulate the hypothesis in terms of the odds ratio <span class="math inline">\(\text{OR}\)</span>, <span class="math inline">\(\mathcal{H}_0: \text{OR} = \frac{\theta_1/(1-\theta_1)}{\theta_2/(1-\theta_2)} = 1\)</span>, and test it in a logistic regression model with a binary outcome and a binary predictor using an asymptotic <span class="math inline">\(z\)</span>-test. Corresponding Bayesian hypothesis tests are available (Dablander et al., 2021).</p>
<p>In <a href="#fig-jab-prop" class="quarto-xref">Figure&nbsp;3</a>, we plot the results of 39 published comparisons of two independent proportions collected by Hoekstra et al.&nbsp;(2018; reanalyzed by Dablander et al., 2021). For both hypothesis tests there is no clear relationship between the one-sided <span class="math inline">\(p\)</span> value and the corresponding Bayes factors—this should not come as a surprise. JAB, on the other hand, is closely linearly related to the corresponding Bayes factors. <!-- For the logistic regression analysis, die JAB is closely related to the exact Bayes factor. --> <!-- As noted above, JAB is based on Wald tests that yield a $chi^2$-distributed or, equivalently, $z$-distributed test statistic.
This assumption holds exactly in these comparisons of two proportions, which explains the close agreement with the exact Bayes factor.
**TODO: The logistic regression analysis also uses a unit information prior, i.e., N(0, 1), right?**
JAB based on Pearson's $\chi^2$-test indicates stronger evidence in favor of the null hypothesis relative to the corresponding Bayes factor for independent Beta-priors (IB) on both proportions.
As in the previous application, the reason is that the two Bayes factors reflect different prior distributions---an exact correspondence is not expected.
In @sec-appendix-bic, we show that JAB closely correpsonds to the approximate Bayes factor based on the Baysian Information Criterion (BIC), which assumes a unit-information pseudo-prior that is similar to JAB's proper unit-information prior. --></p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-jab-prop" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-jab-prop-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="whats-in-a-p-value_files/figure-html/fig-jab-prop-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-jab-prop-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Linear relationships between Bayes factors for point null hypotheses and <span class="math inline">\(p\)</span>-value-based approximations for 39 results of tests comparing two proportions collected by Hoekstra et al.&nbsp;(2018; reanalyzed by Dablander et al., 2021). The top panel compares the results of Pearson’s <span class="math inline">\(\chi^2\)</span>-test to it’s Bayesian analog using independent Beta-priors (IB); the bottom panel compares the results from a logistic regression analysis to its Bayesian analog (LT). Triangles represent the logarithm of the one-sided <span class="math inline">\(p\)</span>-values, circles represent the logarithm of <span class="math inline">\(3 p \sqrt{n}\)</span>-JAB. The color of points indicates the effective sample size.
</figcaption>
</figure>
</div>
</div>
</div>
<p>These examples illustrate that JAB provides an astonishingly good approximation to analytic Bayes factors—especially considering its simplicity.</p>
<section id="assumptions" class="level3 page-columns page-full" data-number="0.4.1">
<h3 data-number="0.4.1" class="anchored" data-anchor-id="assumptions"><span class="header-section-number">0.4.1</span> Assumptions</h3>
<p>Before we use JAB to explore a prinicipled evidential interpretation of <span class="math inline">\(p\)</span> values, we want to highlight the assumptions underlying JAB to clarify the boundary conditions of the approximation. JAB approximates the Bayes factor assuming a normal likelihood,</p>
<p><span class="math display">\[
\text{BF}_{01} = \frac{\text{Pr}(\hat\theta | \mathcal{H}_0)}{\text{Pr}(\hat\theta | \mathcal{H}_1)} = \frac{\mathcal{N}(\hat\theta | \theta_0, \sigma_{\hat\theta})}{\int \mathcal{N}(\hat\theta | \theta, \sigma_{\hat\theta}) g(\theta | \mathcal{H}_1) d\theta} \approx \frac{\mathcal{N}(\hat\theta | \theta_0, \sigma_{\hat\theta})}{g(\hat\theta | \mathcal{H}_1)} = \text{JAB}_{01}.
\]</span></p>
<p>While <span class="math inline">\(\mathcal{N}(\hat\theta | \theta_0, \text{SE}(\hat\theta))\)</span>, the density of <span class="math inline">\(\hat\theta\)</span> under <span class="math inline">\(\mathcal{H}_0\)</span>, is known, the integral in the denominator is not. It is assumed that this integral, and thus, <span class="math inline">\(\text{Pr}(\hat\theta | \mathcal{H}_1) \approx g(\hat\theta | \mathcal{H}_1)\)</span>, that is the prior density of the maximum likelihood estimate under <span class="math inline">\(\mathcal{H}_1\)</span>, <a href="#eq-jab" class="quarto-xref">Equation&nbsp;1</a>. This is an asymptotic approximation based on Laplace’s approximation of the posterior distribution of <span class="math inline">\(\theta\)</span> (<strong>TODO: How can I credit Samuel here?</strong>). Hence, the following assumptions must hold for JAB to be accurate:</p>
<p><strong>Assumption 1</strong>. The sampling distribution of the maximum likelihood estimate is normally distributed, <span class="math inline">\(\hat\theta \sim \mathcal{N}(\hat\theta, \text{SE}(\hat\theta))\)</span>. In many cases, this assumption holds asymptotically (i.e., <span class="math inline">\(n_\text{eff} \to \infty\)</span>) but it can be violated when the sampling distribution is not normal and the sample size is small, also see <a href="#sec-appendix-llr" class="quarto-xref">Section&nbsp;3.2</a>.</p>
<p><strong>Assumption 2</strong>. The posterior distribution is approximately normal, <span class="math inline">\(\theta | \hat\theta \sim \mathcal{N}(\mu_\theta, \sigma_\theta)\)</span>. In general, the validity of this assumption depends on the model and the prior distribution, but holds asymptotically (i.e., <span class="math inline">\(n_\text{eff} \to \infty\)</span>) under quite general conditions (Bernstein-von Mises theorem).</p>
<p><strong>Assumption 3</strong>. The standard error is small or the prior distribution at <span class="math inline">\(\hat\theta\)</span> is mildly curved (concave or convex). The standard error, of course, decreases as the effective sample size <span class="math inline">\(n_\text{eff}\)</span> increases. As illustrated in <a href="#fig-curvature-prior" class="quarto-xref">Figure&nbsp;4</a>, the curvature of the prior distribution depends on the family of the distribution but typically decreases as its scale increases<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>. Hence, the validity of this assumption holds asymptotically or with wide, uninformative priors. Broadly speaking, the data must be informative relative to the prior distribution, <span class="math inline">\(\text{SE}(\hat\theta) \ll \sigma_\theta\)</span> (???). Otherwise JAB will be biased against <span class="math inline">\(\mathcal{H}_0\)</span> when <span class="math inline">\(\hat\theta\)</span> is near the peak and biased against <span class="math inline">\(\mathcal{H}_1\)</span> when <span class="math inline">\(\hat\theta\)</span> is in the tail of the prior distribution. <!-- In small samples---especially with informative priors---we recommend avoiding the asymptotic approximation suggested by Jeffreys and taking prior curvature into account, $g(\hat\theta | \mathcal{H}_1) + 0.5 \; [\text{SE}(\hat\theta)]^2 \; g''(\hat\theta | \mathcal{H}_1)$ (**TODO: How can I credit Samuel here?**). --> <!-- For example, the normal distribution is concave around its peak---in the range $[\mu_\theta - \sigma_\theta, \mu_\theta + \sigma_\theta]$---convex in the tails, and 0 at the inflection point $\mu_\theta \pm \sigma_\theta$. --> <!-- (4) The prior distribution places nonnegligible mass on the maximum likelihood estimate. --> <!-- When holding the position of $\theta$ relative to the prior constant, the curvature tends toward zero as the scale $\sigma_\theta$ increases. --></p>
<div class="no-row-height column-margin column-container"><div id="fn7"><p><sup>7</sup>&nbsp;In small samples, it may be tempting to feel reassured when <span class="math inline">\(\hat\theta\)</span> lies in the tail of the prior distribution where the curvature is close to 0. We caution, however, that the combination of small sample size and obersevations in the tail of the prior distribution often yields non-normal posterior distributions and thus violations of Assumption 2.</p></div></div><div class="cell">
<div class="cell-output-display">
<div id="fig-curvature-prior" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-curvature-prior-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="whats-in-a-p-value_files/figure-html/fig-curvature-prior-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-curvature-prior-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Curvature of prior distributions as a funciton of $ heta$ for different prior scales.
</figcaption>
</figure>
</div>
</div>
</div>
<p>As a rule of thumb, these assumptions are likely to hold in large samples, or for normally distributed <span class="math inline">\(\hat\theta\)</span> if the prior distribution is relatively wide, uninformed and places non-neglibile mass near <span class="math inline">\(\hat\theta\)</span>. In light of this, it is remarkable how well JAB approximates the Bayes factor in practice, <a href="#fig-jab-jzs" class="quarto-xref">Figure&nbsp;2</a> and <a href="#fig-jab-prop" class="quarto-xref">Figure&nbsp;3</a>. Nonetheless, these assumptions imply that JAB is most accurate with objective uninformed prior distributions unless the sample size is large.</p>
<p>When <span class="math inline">\(W\)</span> is calculated from <span class="math inline">\(p\)</span> values (<a href="#eq-w-p" class="quarto-xref">Equation&nbsp;2</a>), it is further assumed that the <span class="math inline">\(p\)</span> was not corrected for multiple comparisons and was derived from a sampling distribution for a constant sample size, see <a href="#sec-desirable-properties" class="quarto-xref">Section&nbsp;0.3</a>. In practice the latter can usually be taken for granted. With these boundary conditions made clear, we now show how JAB offers a prinicipled evidential interpretation of <span class="math inline">\(p\)</span> values.</p>
<p><strong>TODO: Is there an additional assumption about nusance parameters being uncorrelated with test parameter?</strong></p>
</section>
</section>
<section id="the-evidential-value-of-p" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> The evidential value of <span class="math inline">\(p\)</span></h1>
<p>Despite repeated efforts to explain that the <span class="math inline">\(p\)</span> value is not a measure of evidence, proposals to treat it as such continue to be made [p.&nbsp;117, Bland, 2015; p.&nbsp;157, Wasserman, 2004; Muff, Nilsen, O’Hara &amp; Nater, 2021; <span class="citation" data-cites="Cox2011">Cox and Donnelly (<a href="#ref-Cox2011" role="doc-biblioref">2011</a>)</span>]. <a href="#tbl-evidence-categories" class="quarto-xref">Table&nbsp;1</a> lists suggested labels for grades of evidence in favor of <span class="math inline">\(\mathcal{H}_1\)</span> for ranges of <span class="math inline">\(p\)</span> values. Three things are worth noting. First, the suggested grades of evidence follow from typical thresholds of <span class="math inline">\(p\)</span>-values. Second, the suggested grades of evidence are asymmetric: <span class="math inline">\(p &gt; .100\)</span> is said to provide “little or no evidence” in favor of <span class="math inline">\(\mathcal{H}_1\)</span>; only <span class="math inline">\(p &lt; .100\)</span> is suggested to carry evidential value. Third, we have shown the magnitude of the evidence must depend on the effective sample size <span class="math inline">\(n_\text{eff}\)</span>, but the suggested grades of evidence are independent of sample size. JAB can be used evaluate these grades of evidence from a Bayesian perspective.</p>
<div class="cell">
<div id="tbl-evidence-categories" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-evidence-categories-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Categorical interpreations of two-sided <span class="math inline">\(p\)</span> values as evidence against <span class="math inline">\(H_0\)</span> and corresponding approximate Bayes factors.
</figcaption>
<div aria-describedby="tbl-evidence-categories-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div id="tnsfpiluom" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#tnsfpiluom table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#tnsfpiluom thead, #tnsfpiluom tbody, #tnsfpiluom tfoot, #tnsfpiluom tr, #tnsfpiluom td, #tnsfpiluom th {
  border-style: none;
}

#tnsfpiluom p {
  margin: 0;
  padding: 0;
}

#tnsfpiluom .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#tnsfpiluom .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#tnsfpiluom .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#tnsfpiluom .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#tnsfpiluom .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#tnsfpiluom .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#tnsfpiluom .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#tnsfpiluom .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#tnsfpiluom .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#tnsfpiluom .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#tnsfpiluom .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#tnsfpiluom .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#tnsfpiluom .gt_spanner_row {
  border-bottom-style: hidden;
}

#tnsfpiluom .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#tnsfpiluom .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#tnsfpiluom .gt_from_md > :first-child {
  margin-top: 0;
}

#tnsfpiluom .gt_from_md > :last-child {
  margin-bottom: 0;
}

#tnsfpiluom .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#tnsfpiluom .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#tnsfpiluom .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#tnsfpiluom .gt_row_group_first td {
  border-top-width: 2px;
}

#tnsfpiluom .gt_row_group_first th {
  border-top-width: 2px;
}

#tnsfpiluom .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#tnsfpiluom .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#tnsfpiluom .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#tnsfpiluom .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#tnsfpiluom .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#tnsfpiluom .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#tnsfpiluom .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#tnsfpiluom .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#tnsfpiluom .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#tnsfpiluom .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#tnsfpiluom .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#tnsfpiluom .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#tnsfpiluom .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#tnsfpiluom .gt_left {
  text-align: left;
}

#tnsfpiluom .gt_center {
  text-align: center;
}

#tnsfpiluom .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#tnsfpiluom .gt_font_normal {
  font-weight: normal;
}

#tnsfpiluom .gt_font_bold {
  font-weight: bold;
}

#tnsfpiluom .gt_font_italic {
  font-style: italic;
}

#tnsfpiluom .gt_super {
  font-size: 65%;
}

#tnsfpiluom .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#tnsfpiluom .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#tnsfpiluom .gt_indent_1 {
  text-indent: 5px;
}

#tnsfpiluom .gt_indent_2 {
  text-indent: 10px;
}

#tnsfpiluom .gt_indent_3 {
  text-indent: 15px;
}

#tnsfpiluom .gt_indent_4 {
  text-indent: 20px;
}

#tnsfpiluom .gt_indent_5 {
  text-indent: 25px;
}

#tnsfpiluom .katex-display {
  display: inline-flex !important;
  margin-bottom: 0.75em !important;
}

#tnsfpiluom div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {
  height: 0px !important;
}
</style>

<table class="gt_table do-not-create-environment cell caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
<colgroup>
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="gt_col_headings gt_spanner_row header">
<th rowspan="2" id="a$$p$$" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">$$p$$</th>
<th colspan="2" id="Grades of evidence" class="gt_center gt_columns_top_border gt_column_spanner_outer" data-quarto-table-cell-role="th" scope="colgroup"><div class="gt_column_spanner">
Grades of evidence
</div></th>
<th colspan="3" id="Bayesian evidence" class="gt_center gt_columns_top_border gt_column_spanner_outer" data-quarto-table-cell-role="th" scope="colgroup"><div class="gt_column_spanner">
Bayesian evidence
</div></th>
<th rowspan="2" id="a$$\max(\mathcal{L}_1-/-\mathcal{L}_0)$$" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">$$\max(\mathcal{L}_1 / \mathcal{L}_0)$$</th>
</tr>
<tr class="gt_col_headings even">
<th id="Bland-(2015)" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">Bland (2015)</th>
<th id="Wasserman-(2004)" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">Wasserman (2004)</th>
<th id="a$$\text{JAB}_{10}(n_\text{eff}-=-30)$$" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">$$\text{JAB}_{10}(n_\text{eff} = 30)$$</th>
<th id="a$$\text{JAB}_{10}(n_\text{eff}-=-8)$$" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">$$\text{JAB}_{10}(n_\text{eff} = 8)$$</th>
<th id="a$$\max(\text{BF}^{\mathcal{N}}_{10})$$" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">$$\max(\text{BF}^{\mathcal{N}}_{10})$$</th>
</tr>
</thead>
<tbody class="gt_table_body">
<tr class="odd">
<td class="gt_row gt_left" headers="$$p$$">$$(1.000, .100]$$</td>
<td class="gt_row gt_left" headers="Bland (2015)">Little or no evidence</td>
<td class="gt_row gt_left" headers="Wasserman (2004)">Little or no evidence</td>
<td class="gt_row gt_left" headers="$$\text{JAB}_{10}(n_\text{eff} = 30)$$">$$(0.18, 0.68]$$</td>
<td class="gt_row gt_left" headers="$$\text{JAB}_{10}(n_\text{eff} = 8)$$">$$(0.35, 1.15]$$</td>
<td class="gt_row gt_left" headers="$$\max(\text{BF}^{\mathcal{N}}_{10})$$">$$(1.00, 1.43]$$</td>
<td class="gt_row gt_left" headers="$$\max(\mathcal{L}_1 / \mathcal{L}_0)$$">$$(1.00, 3.87]$$</td>
</tr>
<tr class="even">
<td class="gt_row gt_left" headers="$$p$$">$$(.100, .050]$$</td>
<td class="gt_row gt_left" headers="Bland (2015)">Weak evidence</td>
<td class="gt_row gt_left" headers="Wasserman (2004)">Weak evidence</td>
<td class="gt_row gt_left" headers="$$\text{JAB}_{10}(n_\text{eff} = 30)$$">$$(0.68, 1.17]$$</td>
<td class="gt_row gt_left" headers="$$\text{JAB}_{10}(n_\text{eff} = 8)$$">$$(1.15, 1.90]$$</td>
<td class="gt_row gt_left" headers="$$\max(\text{BF}^{\mathcal{N}}_{10})$$">$$(1.43, 2.11]$$</td>
<td class="gt_row gt_left" headers="$$\max(\mathcal{L}_1 / \mathcal{L}_0)$$">$$(3.87, 6.83]$$</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left" headers="$$p$$">$$(.050, .010]$$</td>
<td class="gt_row gt_left" headers="Bland (2015)">Evidence</td>
<td class="gt_row gt_left" headers="Wasserman (2004)">Strong evidence</td>
<td class="gt_row gt_left" headers="$$\text{JAB}_{10}(n_\text{eff} = 30)$$">$$(1.17, 4.51]$$</td>
<td class="gt_row gt_left" headers="$$\text{JAB}_{10}(n_\text{eff} = 8)$$">$$(1.90, 6.44]$$</td>
<td class="gt_row gt_left" headers="$$\max(\text{BF}^{\mathcal{N}}_{10})$$">$$(2.11, 6.50]$$</td>
<td class="gt_row gt_left" headers="$$\max(\mathcal{L}_1 / \mathcal{L}_0)$$">$$(6.83, 27.59]$$</td>
</tr>
<tr class="even">
<td class="gt_row gt_left" headers="$$p$$">$$(.010, .001]$$</td>
<td class="gt_row gt_left" headers="Bland (2015)">Strong evidence</td>
<td class="gt_row gt_left" headers="Wasserman (2004)">Very strong evidence</td>
<td class="gt_row gt_left" headers="$$\text{JAB}_{10}(n_\text{eff} = 30)$$">$$(4.51, 34.22]$$</td>
<td class="gt_row gt_left" headers="$$\text{JAB}_{10}(n_\text{eff} = 8)$$">$$(6.44, 40.34]$$</td>
<td class="gt_row gt_left" headers="$$\max(\text{BF}^{\mathcal{N}}_{10})$$">$$(6.50, 41.38]$$</td>
<td class="gt_row gt_left" headers="$$\max(\mathcal{L}_1 / \mathcal{L}_0)$$">$$(27.59, 224.48]$$</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left" headers="$$p$$">$$(.001, .000)$$</td>
<td class="gt_row gt_left" headers="Bland (2015)">Very strong evidence</td>
<td class="gt_row gt_left" headers="Wasserman (2004)"></td>
<td class="gt_row gt_left" headers="$$\text{JAB}_{10}(n_\text{eff} = 30)$$">$$(34.22, \infty)$$</td>
<td class="gt_row gt_left" headers="$$\text{JAB}_{10}(n_\text{eff} = 8)$$">$$(40.34, \infty)$$</td>
<td class="gt_row gt_left" headers="$$\max(\text{BF}^{\mathcal{N}}_{10})$$">$$(41.38, \infty)$$</td>
<td class="gt_row gt_left" headers="$$\max(\mathcal{L}_1 / \mathcal{L}_0)$$">$$(224.48, \infty)$$</td>
</tr>
</tbody><tfoot class="gt_footnotes">
<tr class="odd">
<td colspan="7" class="gt_footnote">(_{10}) assuming a unit-information prior centered on the test-value (<em>0). ((^{}</em>{10})) is the upper limit on the evidence for (_1) when the prior distribution is normal <span class="citation" data-cites="Edwards1963">(p.&nbsp;231, <a href="#ref-Edwards1963" role="doc-biblioref">Edwards, Lindman, and Savage 1963</a>)</span>.</td>
</tr>
</tfoot>

</table>

</div>
</div>
</div>
</figure>
</div>
</div>
<p><a href="#fig-p-jab" class="quarto-xref">Figure&nbsp;5</a> A shows how <span class="math inline">\(p\)</span> relates to Bayesian evidence as a function of the effective sample size. As is clear form <a href="#eq-jab" class="quarto-xref">Equation&nbsp;1</a>, there can be no unique relationship between <span class="math inline">\(p\)</span> and the Bayes factor, as the latter always depends on the prior distribution. <!-- The figure gives the approximate $\text{JAB}_{10}$ for objective testing, i.e., $A = \sqrt{\pi/2}$ as suggested by Jeffreys (1961, p. 277)[^jab-uip]. --> The figure gives <span class="math inline">\(\text{JAB}_{10}\)</span> assuming a common prior choice in objective testing, the unit-information prior centered on the test-value <span class="math inline">\(\theta_0\)</span> <span class="citation" data-cites="Wagenmakers2022">(p.&nbsp;8, <a href="#ref-Wagenmakers2022" role="doc-biblioref">Wagenmakers 2022</a>)</span>,</p>
<p><span id="eq-jab-uip"><span class="math display">\[
\text{JAB}_{01} = \sqrt{n_\text{eff}} \; \exp\big[ -0.5 \; (n_\text{eff}-1) / n_\text{eff} ~~ Q_{\chi^2(1)}(1-p) \big].
\tag{3}\]</span></span></p>
<p>This prior is sufficiently wide that results for small samples are tenable. The solid lines represent commonly used grades of Bayesian evidence (Jeffreys, 1961; Lee &amp; Wagenmakers, 2013). Note that both axes are on log-scale.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-p-jab" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-p-jab-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="whats-in-a-p-value_files/figure-html/fig-p-jab-1.png" class="img-fluid figure-img" width="960">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-p-jab-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Relationship between two-sided <span class="math inline">\(p\)</span>-value and <span class="math inline">\(\text{JAB}_{10}\)</span> as a function of effective sample size <span class="math inline">\(n_\text{eff}\)</span>. Solid lines represent the <span class="math inline">\(\text{JAB}_{10}\)</span> for a unit-information prior centered on the test-value <span class="math inline">\(\theta_0\)</span>. <strong>A</strong> Color represents the continuous evidence with the grades of evidence suggested by Lee &amp; Wagenmakers (2013). The dotted lines represent the <span class="math inline">\(\text{JAB}_{10}\)</span> for a unit-information prior centered on the maximum likelihood estimate <span class="math inline">\(\hat\theta\)</span>. <strong>B</strong> Illustration of the shift of the grades of evidence implied by <span class="math inline">\(p\)</span> from small (<span class="math inline">\(n &lt; 50\)</span>) to large samples (<span class="math inline">\(n &gt; 250\)</span>).
</figcaption>
</figure>
</div>
</div>
</div>
<p>Several important consequences for the evidential interpration of <span class="math inline">\(p\)</span> follow. First, it is clear from <a href="#fig-p-jab" class="quarto-xref">Figure&nbsp;5</a> A that a principled interpretation of <span class="math inline">\(p\)</span>-values as continuous measures of evidence must take the effective sample size into account. The grades of evidence suggested by Bland (2015) approximately correspond to the Bayesian grades of evidence suggested by Lee &amp; Wagenmakers (2013), if the effective sample size is <span class="math inline">\(n_\text{eff} \approx 8\)</span>. This is, however, close to the upper bound on the evidence for this class of prior distribution, <span class="math inline">\(\max(\text{BF}^{\mathcal{N}}_{10})\)</span> <span class="citation" data-cites="Edwards1963">(p.&nbsp;231, <a href="#ref-Edwards1963" role="doc-biblioref">Edwards, Lindman, and Savage 1963</a>)</span>, <a href="#tbl-evidence-categories" class="quarto-xref">Table&nbsp;1</a>. As <span class="math inline">\(n_\text{eff}\)</span> increases (or decrease), the suggested grades quickly overstate the Bayesian evidence for <span class="math inline">\(\mathcal{H}_1\)</span>. The grades of evidence suggested by Wasserman (2004) overstate the Bayesian evidence even when <span class="math inline">\(n_\text{eff} \approx 8\)</span>—even though <span class="citation" data-cites="Wasserman2000">Wasserman (<a href="#ref-Wasserman2000" role="doc-biblioref">2000</a>)</span> agrees with the grades of Bayesian evidence suggested by Lee &amp; Wagenmakers (2013). For <span class="math inline">\(p &lt; .10\)</span> and <span class="math inline">\(n_\text{eff} &gt; 20\)</span>, as the effective sample size increases <span class="math inline">\(\log(p)\)</span> must decreases approximately linearly to yield constant evidence<!--[^approx-linearity]--> (Benjamin et al., XXXX). Hence, changes in effective sample size noticably affect the evidence in <span class="math inline">\(p\)</span> in small samples, but are less consequential in larger samples, <a href="#fig-p-jab" class="quarto-xref">Figure&nbsp;5</a> B. Muff, Nilsen, O’Hara and Nater (2021) argue that this deceleration renders sample size irrelevant for the evidential interpretation of <span class="math inline">\(p\)</span> suggested by Bland (2015). <a href="#fig-p-jab" class="quarto-xref">Figure&nbsp;5</a> B shows this to be incorrect (also see Hartig &amp; Barraquand, 2022). Assume that typical samples in their field of research are large enough that changing the sample size changes the evidence neglibably, e.g.&nbsp;<span class="math inline">\(n_\text{eff} &gt; 300\)</span>. At this point Bland’s grades of evidence overstate the evidence for <span class="math inline">\(\mathcal{H}_1\)</span>. <!-- While in small samples the suggested grades of evidence for $p$ correspond reasonably well to the Bayesian grades of evidence, in large samples they are biased against $\mathcal{H}_0$. --> For example, in small samples (<span class="math inline">\(n_\text{eff} &lt; 20\)</span>) <span class="math inline">\(.01 &lt; p &lt; .001\)</span> usually implies moderate to very strong evidence for <span class="math inline">\(\mathcal{H}_1\)</span>, but in larger samples (<span class="math inline">\(n_\text{eff} = 300\)</span>) this evidence is strong at best but usually anecdotal or moderate. In other words, the evidence for <span class="math inline">\(\mathcal{H}_1\)</span> is shifted down relative to Bland’s by a full grade.</p>
<!-- [^approx-linearity]: We find that the linear relationship is well approximated by a slight elaboration of this expression, i.e., $\text{JAB}_{01} = p^{9/10} \; \sqrt{n_\text{eff}} \; (\pi - 1)$ and hence $\log(p) = 0.9 \log(\text{JAB}_{01}) - 0.556 \log(n_\text{eff}) - 0.9 \log(\pi - 1)$. -->
<p>Second, given <span class="math inline">\(p\)</span> implies less evidence for <span class="math inline">\(\mathcal{H}_1\)</span> as the effective sample size increases, but in small samples this trend typically reverses. As shown in <a href="#fig-p-jab" class="quarto-xref">Figure&nbsp;5</a> B and highlighted in <a href="#fig-p-jab" class="quarto-xref">Figure&nbsp;5</a> A, when the unit-information prior is centered on the test value <span class="math inline">\(\theta_0\)</span>, the evidence for <span class="math inline">\(\mathcal{H}_1\)</span> implied by <span class="math inline">\(p\)</span> levels off and decreases as the effective sample size becomes very small, <span class="math inline">\(n_\text{eff} &lt; 8\)</span>. However, as shown by the dotted curves in <a href="#fig-p-jab" class="quarto-xref">Figure&nbsp;5</a> A, when the prior is centered on the maximum likelihood estimate <span class="math inline">\(\hat\theta\)</span>, the evidence for <span class="math inline">\(\mathcal{H}_1\)</span> continous to increase with the effective sample size. The difference is most prominent in small samples. The same prior underlies another popular approximation to the Bayes factor, the <span class="math inline">\(\text{BIC}\)</span>. Again, this prior distribution amounts to using the data twice and is best considered a lower bound on the Bayes factor for the unit-information prior, in particular in small samples <span class="math inline">\(n_\text{eff} &lt; 30\)</span> (Held &amp; Ott, 2018).</p>
<p>A third important consequence that evident from <a href="#fig-p-jab" class="quarto-xref">Figure&nbsp;5</a> A pertains to the evidence implied by <span class="math inline">\(p &gt; 0.1\)</span>. In line with Bland (2015) and Wasserman (2004), in very small samples (<span class="math inline">\(n_\text{eff} &lt; 9\)</span>) such results provides little or no evidence for either <span class="math inline">\(\mathcal{H}_1\)</span> or <span class="math inline">\(\mathcal{H}_0\)</span>. However, this is not true in general. In moderate (<span class="math inline">\(9 &lt; n_\text{eff} &lt; 100\)</span>) and large samples (<span class="math inline">\(100 &lt; n_\text{eff} &lt; 900\)</span>) it is possible to obtain moderate to strong evidence for <span class="math inline">\(\mathcal{H}_0\)</span>! Hence, in sufficiently large samples $.1 &lt; p &lt; 1 $ can be informative and provide meaningful evidence for the absence of an effect.</p>
<p>Lastly, JAB can be used to derive lower and upper bounds on the Bayes factor. For simplicity, consider a unit-information prior centered on the maximum likelihood estimate <span class="math inline">\(\hat\theta\)</span>, i.e., <span class="math inline">\(A = 1\)</span> in <a href="#eq-jab" class="quarto-xref">Equation&nbsp;1</a>. Note that, while mathematically convenient, a prior distribution centered on <span class="math inline">\(\hat\theta\)</span> amounts to using the data twice (to inform the prior distribution under <span class="math inline">\(\mathcal{H}_1\)</span> and to test this hypothesis) and will bias the evidence in favor of <span class="math inline">\(\mathcal{H}_1\)</span>. It can in itself be considered a lower bound on Bayes factors for the unit-information prior. The lower bound on this Bayes factor for a given <span class="math inline">\(p\)</span> is reached when <span class="math inline">\(n_\text{eff} = 1\)</span>,</p>
<p><span class="math display">\[
\min(\text{JAB}_{01}) = \exp\left[-0.5~\left[Q_{\mathcal{N(0,1)}}(p/2)\right]^2\right].
\]</span></p>
<p>This is the lower bound on the likelihood ratio [<span class="math inline">\(\max(\mathcal{L}_0 / \mathcal{L}_1)\)</span>; p.&nbsp;228, <span class="citation" data-cites="Edwards1963">Edwards, Lindman, and Savage (<a href="#ref-Edwards1963" role="doc-biblioref">1963</a>)</span>; p.&nbsp;116 <span class="citation" data-cites="Berger1987">Berger and Sellke (<a href="#ref-Berger1987" role="doc-biblioref">1987</a>)</span>], <a href="#tbl-evidence-categories" class="quarto-xref">Table&nbsp;1</a>. For a comprehensive review on other lower bounds on the Bayes factor see the comprehensive review by <span class="citation" data-cites="Held2018">Held and Ott (<a href="#ref-Held2018" role="doc-biblioref">2018</a>)</span>. <!-- As noted by Marsman et al. this approximation assumes a standard normal distribution of the probit-transformed $p$-value und the alternative distribution.
We see here that this assumption holds for a normally distributed test statistic.
For the $t$-test, we show in @sec-appendix-bic that violations of this assumption are tolable for a wide range of $p$ even in moderate sample sizes. --> Conversely, the upper bound on the evidence for <span class="math inline">\(\mathcal{H}_0\)</span> for a given effective sample size <span class="math inline">\(n_\text{eff}\)</span> is reached when <span class="math inline">\(p \to 1\)</span> and thus</p>
<p><span class="math display">\[
\max(\text{JAB}_{01}) = \sqrt{n_\text{eff}}.
\]</span></p>
<p>This simple expression holds regardless of the center of the unit-information prior and is a useful reference point when evaluating claims about the absence of an effect based on a non-significant NHST. Bounds can similary be derived for other prior distributions.</p>
<!-- It is, however, possible to calculate the upper bound of the evidence for the alternative hypothesis across a wide range of sensible prior distributions (e.g., unimodal and symmetrical around 0; Sellke, Bayarri, & Berger, 2001; Berger & Sellke, 1987), the so-called Vovk-Sellke Maximum $p$-Ratio (MS-VPR),

$$
\text{MS-VPR}_{01} =

\begin{cases}
-e~p~\log(p) & \text{if } & p < 1/e \\
                  1 & \text{if } & \text{otherwise}, \\
\end{cases}
$$

where the $p$-value corresponds to a two-sided alternative hypothesis.
As @tbl-evidence-categories shows, the $\text{MS-VPR}$ broadly corroborates our assessment of the suggested grades of evidence for $p$ based on $\text{JAB}$.
**TODO: How is it possible that JAB can indicate stronger evidence than the maximum implied by MS-VPR?**
**This is because this approximation does not work well in small samples, annurev-statistics, Held & Ott (2018)** -->
<!--
At $n = 1$ $\text{JAB}_{10}$ assuming $A = 1$ reduces to the lower Likelihood ratio bound (Berger & Sellke, 1987; @sec-appendix-bic),



::: {.cell}

:::




$$
\max(\mathcal{L}_1 / \mathcal{L}_0) = \exp(-0.5 \chi^2(1)).
$$

This roughly corresponds to half of the maximum Bayes factor for any prior distribution symmetrical round 0 (i.e., two spikes; Berger & Sellke, 1987; Sellke, Bayarri, & Berger 2001, Table 3).
The VS-MPR roughly corresponds to the maximum Bayes factor for any symmetrical, unimodal prior distribution centered on 0.
-->
<!--
We can solve this expression for $p$ to determine what $p$-values correspond to which evidence category in the ideal case,

$$
p = \exp(W(- \text{BF} / e)).
$$

where $W$ is the Lambert W function.
As @tbl-asymptotic-min-bf-categories shows, *in the best case* $.037 < p < .008$ provides moderate and $.008 < p < .002$ provides strong evidence in large samples.
This illustrates, that when Muff et al. (2021b) appeal to the large-sample stability the $p$-$\text{BF}$ association, they must assume very large samples and a prior distribution that maximizes the evidence.



::: {#tbl-asymptotic-min-bf-categories .cell tbl-cap='Evidence categories for $p$-values based on the maximum Bayes factor for the alternative hypothesis.'}

:::


-->
<!-- 
Lower bound on the Bayes factor

$$
\min(\text{JAB}_{01}) = A \exp\left[-0.5~Q_{\chi^2(1)}(1-p)\right],
$$

which is

$$
\min(\text{JAB}_{01}) = A \exp\left[-0.5~\left[Q_{\mathcal{N(0,1)}}(p/2)\right]^2\right]
$$

but this is silly because we assume $n_\text{eff} = 1$ and we usually know better.

More interesting:

$$
\begin{aligned}
\max(\text{JAB}_{01}) & = A \sqrt{n_\text{eff}} \\
n_\text{eff} & = (\max(\text{JAB}_{01}) / A)^2
\end{aligned}
$$

-->
</section>
<section id="conclusion" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Conclusion</h1>
<p>Interpreting <span class="math inline">\(p\)</span> values as a measure of statistical evidence for a hypothesis is suggested in statistics text books (p.&nbsp;117, Bland, 2015; p.&nbsp;157, Wasserman, 2004; <span class="citation" data-cites="Cox2011">Cox and Donnelly (<a href="#ref-Cox2011" role="doc-biblioref">2011</a>)</span>) and continues to be pervasive in research practice (Gigerenzer, &lt;<span class="citation" data-cites="Gigerenzer2018">Gigerenzer (<a href="#ref-Gigerenzer2018" role="doc-biblioref">2018</a>)</span>&gt;; &lt;<span class="citation" data-cites="Cohen1994">Cohen (<a href="#ref-Cohen1994" role="doc-biblioref">1994</a>)</span>&gt;). Calls to abandon this practice [e.g., <strong>???</strong>, <span class="citation" data-cites="Hubbard2008">Hubbard and Lindsay (<a href="#ref-Hubbard2008" role="doc-biblioref">2008</a>)</span>; Royall, 1997; Goodman &amp; Royall, 1988] have had limited success. We hope our discussion contributes to educating researchers about the limitations of <span class="math inline">\(p\)</span> values, but we realize that education alone is not effective in changing behavior <span class="citation" data-cites="Albarracn2024 Wood2024">(<a href="#ref-Albarracn2024" role="doc-biblioref">Albarracín, Fayaz-Farkhad, and Granados Samayoa 2024</a>; <a href="#ref-Wood2024" role="doc-biblioref">Wood 2024</a>)</span>. Instead of just asking someone to quit a bad habit, it is sometimes more effective to offer them a better alternative <span class="citation" data-cites="Albarracn2024">(<a href="#ref-Albarracn2024" role="doc-biblioref">Albarracín, Fayaz-Farkhad, and Granados Samayoa 2024</a>)</span>. But adopting better alternatives is difficult when they add friction and <span class="math inline">\(p\)</span> values are often much easier to calculate than Bayes factors. So in this paper, we provide a simple formula to transform <span class="math inline">\(p\)</span> values into an approximate measure of evidence requiring only the effective sample size: Jeffreys’s approximate Bayes factor [JAB; Jeffreys, 1936; <span class="citation" data-cites="Wagenmakers2022">Wagenmakers (<a href="#ref-Wagenmakers2022" role="doc-biblioref">2022</a>)</span>], <a href="#eq-jab" class="quarto-xref">Equation&nbsp;1</a>. We have demonstrated that JAB is a surprisingly good approximation to the Bayes factors from objective tests of mean comparisons and proportions across a range of realistic scenarios, <a href="#fig-jab-jzs" class="quarto-xref">Figure&nbsp;2</a> and <a href="#fig-jab-prop" class="quarto-xref">Figure&nbsp;3</a>. And we have illustrated how the evidence implied by a <span class="math inline">\(p\)</span> value is not constant but depends on the effective sample size, <a href="#fig-p-jab" class="quarto-xref">Figure&nbsp;5</a>.</p>
<p>We believe that JAB and <a href="#fig-p-jab" class="quarto-xref">Figure&nbsp;5</a> can be useful tools for researchers, reviewers, and readers to assess claims of both presence and absence of effects—regardless of whether the data were peaked at during data collection. And in case <a href="#eq-jab-uip" class="quarto-xref">Equation&nbsp;3</a> still causes too much friction, <span class="citation" data-cites="Wagenmakers2022">Wagenmakers (<a href="#ref-Wagenmakers2022" role="doc-biblioref">2022</a>)</span> has suggested an even simpler approximation, where <span class="math inline">\(\text{JAB}_{01} \approx 3 p \sqrt{n_\text{eff}}\)</span>, if <span class="math inline">\(p \leq .10\)</span> (their Eq. 9).</p>
<!-- 
$$
\text{JAB}_{01} \approx
\begin{cases}
\begin{aligned}
3 & p & \sqrt{n} & \text{if } & p \leq .10 \\
& \sqrt{p} & \sqrt{n} & \text{if } .10 < & p \leq .50 \text{ (simpler)} \\
\frac{4}{3} & p^{2/3} & \sqrt{n} & \text{if } .10 < & p \leq .50 \text{ (more precise)} \\
& p^{1/4} & \sqrt{n} & \text{if } & p > .50
\end{aligned}
\end{cases}
$$
-->
<!-- We have found that a closer, albeit slightly more involved, approximation can be achieved through what we call the $p \sqrt{n}~\pi$-rule:

$$
\text{JAB}_{01} \approx
\begin{cases}
\begin{aligned}
p^{9/10} \sqrt{n} & (\pi-1) & \text{if } & p < 0.1 \\
p^{2/3}~ \sqrt{n} & 4/\pi & \text{if } 0.1 \leq & p < 0.6 \\
p^{1/5}~ \sqrt{n} &       & \text{if } & p \geq 0.6
\end{aligned}
\end{cases}
$$

pnnats-rule

$$
\text{JAB}_{01} \approx
\begin{cases}
\begin{aligned}
p^{9/10} \sqrt{n} &  \phantom{e} \pi \log(2) & \text{if } & p < 0.1 \\
p^{2/3}~ \sqrt{n} &           e  \pi \log(2) & \text{if } 0.1 \leq & p < 0.6 \\
p^{1/5}~ \sqrt{n} &                          & \text{if } & p \geq 0.6
\end{aligned}
\end{cases}
$$ 
-->
<!-- To be clear, the $3 p \sqrt{n}$-rule is an approximation to an approximate Bayes factor.
It is a simple rule of thumb that can be used to quickly gauge the evidence implied by a given $p$ value and sample size.
Using the full JAB formula yields a more precise approximation. -->
<!-- ## Limitation

- We need uncorrected, fixed-n p's (or be able to calculate them from the reported information)
- JAB: Assume that the sampling distribution of the MLE is normal, and that se(θ) ≪ σg, where σg is the scale of the prior distribution g(θ).
  - Won't work for small samples or informed priors?
- It all depends on the prior > Use full JAB approximation (set \sigma = 1, standardized effects) -->
</section>



<div id="quarto-appendix" class="default"><section id="appendix" class="level1 appendix" data-number="3"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">3</span> Appendix</h2><div class="quarto-appendix-contents">



</div></section><section id="sec-appendix-n-eff" class="level2 appendix" data-number="3.1"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">3.1</span> What is <span class="math inline">\(n_\text{eff}\)</span>?</h2><div class="quarto-appendix-contents">

<p>In the main text, we largely glossed over an imporant issue when calculating JAB: What is the effective sample size <span class="math inline">\(n_\text{eff}\)</span> in <a href="#eq-jab" class="quarto-xref">Equation&nbsp;1</a>? The term <span class="math inline">\(\sqrt{n_\text{eff}}\)</span> is the denominator of the standard error of the maximum likelihood estimate, <span class="math inline">\(\text{SE}(\hat \theta)\)</span>—it is a function of sample size and scales the standard deviation of the sampling distribution of the <span class="math inline">\(\hat \theta\)</span>. Hence, the correct definition of <span class="math inline">\(n_\text{eff}\)</span> depends on <span class="math inline">\(\theta\)</span>. <span class="citation" data-cites="Berger2013">Berger, Bayarri, and Pericchi (<a href="#ref-Berger2013" role="doc-biblioref">2013</a>)</span> provide a general treatment of effective sample size in the linear model for the BIC but equally applies to JAB. In the following, we show a simpler derivation for the applications shown in in <a href="#fig-jab-jzs" class="quarto-xref">Figure&nbsp;2</a> and <a href="#fig-jab-prop" class="quarto-xref">Figure&nbsp;3</a>.</p>



</div></section><section id="effective-sample-size-for-one-sample-t-tests" class="level3 appendix" data-number="3.1.1"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">3.1.1</span> Effective sample size for one-sample <span class="math inline">\(t\)</span>-tests</h2><div class="quarto-appendix-contents">

<p>In the case of a one-sample <span class="math inline">\(t\)</span>-test, <span class="math inline">\(\hat \theta = \hat \mu\)</span>—the sample mean—and the standard error is <span class="math inline">\(\text{SE}(\hat \theta = \hat \mu) = \hat \sigma / \sqrt{n}\)</span>. Here, the effective sample size is simply the number of observations, <span class="math inline">\(n_\text{eff} = n\)</span>. Similarly, in the paired-sample <span class="math inline">\(t\)</span>-test, <span class="math inline">\(\hat \theta = \hat \mu_\Delta\)</span>—the sample mean of the differences between the paired observations—and the standard error is <span class="math inline">\(\text{SE}(\hat \theta = \hat \mu_\Delta) = \hat \sigma_\Delta / \sqrt{n_\Delta}\)</span>. Now, the effective sample size is the number of differences or, equivalently, the number of pairs, <span class="math inline">\(n_\text{eff} = n_\Delta\)</span>. In the independent sample <span class="math inline">\(t\)</span>-test, <span class="math inline">\(\hat \theta = \hat \mu_1 - \hat \mu_2 = \Delta \hat \mu\)</span>—the difference between the sample means—and, assuming homogeneous variances, the standard error is based on pooled estimate of the standard deviation. In this case, the effective sample size is half the harmonic mean <span class="math inline">\(H\)</span> of the sample sizes,</p>
<p><span class="math display">\[
n_\text{eff} = H(n_1, n_2) / 2 = (n_2~n_1) / (n_1 + n_2),
\]</span></p>
<p>an average dominated by the smaller sample size. In balanced designs, where <span class="math inline">\(n_1 = n_2\)</span>, this expression simplifies to <span class="math inline">\(n_\text{eff} = (n_1 + n_2) / 4\)</span>, the arithmetic mean. For the interested reader, we provide the equations for the effective sample size in the more general case of unequal variances—Welch’s <span class="math inline">\(t\)</span>-test—and the tests of independent proportions in below. To summarize, the <span class="math inline">\(n_\text{eff}\)</span> in JAB is the factor that scales the standard error of <span class="math inline">\(\hat \theta\)</span> and is a <em>function</em> of sample size. <span class="math inline">\(n_\text{eff}\)</span> is calculated differently for each model and parameterization. Determining the correct <span class="math inline">\(n_\text{eff}\)</span> can be difficult in more complex models, which is why</p>
</div></section><section id="effective-sample-size-for-independent-sample-t-tests" class="level3 appendix" data-number="3.1.2"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">3.1.2</span> Effective sample size for independent-sample <span class="math inline">\(t\)</span>-tests</h2><div class="quarto-appendix-contents">

<p>In the independent sample <span class="math inline">\(t\)</span>-test, <span class="math inline">\(\hat \theta = \hat \mu_1 - \hat \mu_2 = \Delta \hat \mu\)</span>—the difference between the sample means—and the standard error is</p>
<p><span class="math display">\[
\begin{aligned}
\text{SE}(\hat \theta = \Delta \hat \mu) &amp; = \hat \sigma_p \cdot \sqrt{1/n_1 + 1/n_2} \\
&amp; = \hat \sigma_p \cdot \sqrt{(n_1 + n_2) / (n_1 \cdot n_2)} \\
&amp; = \frac{ \hat \sigma_p }{ \sqrt{(n_1 \cdot n_2) / (n_1 + n_2)}},
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(\hat \sigma_p\)</span> is the pooled estiamte of the standard deviation, i.e.&nbsp;the assumedly <em>common</em> standard deviation estimated using the data from both samples. So here, the effective sample size <span class="math inline">\(n_\text{eff}\)</span> is half the harmonic mean of the two sample sizes,</p>
<p><span class="math display">\[
n_\text{eff} = 0.5 \cdot H(n_1, n_2) = (n_1 \cdot n_2) / (n_1 + n_2),
\]</span></p>
<p>an average dominated by the smaller sample size. When the variance are unequal, and Welch’s <span class="math inline">\(t\)</span>-test is reported, the standard error is based on separate estimates of the standard deviation,</p>
<p><span class="math display">\[
\text{SE}(\hat \theta = \Delta \hat \mu) = \sqrt{\hat \sigma_1^2 / n_1 + \hat \sigma_2^2 / n_2}.
\]</span></p>
<p>To obtain the effective sample size in the above form, we define a variance ratio <span class="math inline">\(w = s^2_1/s^2_2\)</span>, which yields</p>
<p><span class="math display">\[
\begin{aligned}
\text{SE}(\hat \theta = \Delta \hat \mu) &amp; = \hat \sigma_1 \cdot \sqrt{1 / n_1 + w / n_2} \\
&amp; = \hat \sigma_1 \cdot \sqrt{(n_1 + wn_2) / (n_1 \cdot n_2)} \\
&amp; = \frac{ \hat \sigma_1 }{ \sqrt{(n_1 \cdot n_2) / (n_1 + wn_2)}}.
\end{aligned}
\]</span></p>
<p>Hence, <span class="math inline">\(n_\text{eff} = (n_1 \cdot n_2) / (n_1 + wn_2)\)</span>, which is half of harmonic mean of the sample sizes weighted by the variance ratio <span class="math inline">\(w\)</span>.</p>
<p>See <span class="citation" data-cites="Berger2013">Berger, Bayarri, and Pericchi (<a href="#ref-Berger2013" role="doc-biblioref">2013</a>)</span> for more general derivation of the effective sample size in the linear model.</p>
</div></section><section id="effective-sample-size-for-two-independent-proportions" class="level3 appendix" data-number="3.1.3"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">3.1.3</span> Effective sample size for two independent proportions</h2><div class="quarto-appendix-contents">

<p>For the test of log odds ratio the standard error can be calculated from the cell frequencies as,</p>
<p><span class="math display">\[
\text{SE}(\hat{\theta} = \log{\text{OR}}) = \sqrt{\frac{1}{y_1 + 0.5} + \frac{1}{y_2 + 0.5} + \frac{1}{n_1 - y_1 + 0.5} + \frac{1}{n_2 - y_2 + 0.5}},
\]</span></p>
<p>(e.g., Anscombe, 1956; Gart, 1966; Haldane, 1956; cf.&nbsp;Agresti, 1999) which implies that the effective sample size for JAB is,</p>
<p><span class="math display">\[
n_\text{eff} = \left(\frac{1}{y_1} + \frac{1}{y_2} + \frac{1}{n_1 - y_1} + \frac{1}{n_2 - y_2}\right)^{-1}.
\]</span></p>
<!--
For the test in proportion-space, the effective sample size seems to be

$$
n = \frac{1}{((1/(n_1+1) + 1/(n_2+1)) * (y_1 + y_2 + 1)/(n_1 + n_2 + 2) * (1 - (y_1 + y_2 + 1)/(n_1 + n_2 
    + 1)) * \exp(2))},
$$

where this corresponds to the inverse of the standard error, but I have no idea, why need the extra factor of $\exp{2}$.
But if it's not there, the Bayes factor is too large.
-->
<p>For the <span class="math inline">\(\chi^2\)</span>-test, the effective sample size can be derived from the formula for the confidence interval of the difference between two proportions <span class="citation" data-cites="Beal1987">(<a href="#ref-Beal1987" role="doc-biblioref">Beal 1987</a>)</span>,</p>
<p><span class="math display">\[
n_\text{eff} = \left[\frac{\hat{\pi}_1(1-\hat{\pi}_1)}{n_1} + \frac{\hat{\pi}_2(1-\hat{\pi}_2)}{n_2}\right]^{-1}.
\]</span></p>
</div></section><section id="sec-appendix-llr" class="level2 appendix" data-number="3.2"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">3.2</span> <span class="math inline">\(p\)</span>-based JAB for independent and dependent sample <span class="math inline">\(t\)</span>-tests</h2><div class="quarto-appendix-contents">

<p>In <a href="#eq-jab" class="quarto-xref">Equation&nbsp;1</a>, <span class="math inline">\(W\)</span> is used to approximate the likelihood ratio <span class="citation" data-cites="Wilks1938">(Wilk’s theorem, <a href="#ref-Wilks1938" role="doc-biblioref">Wilks 1938</a>)</span>, i.e., as <span class="math inline">\(n \to \infty\)</span></p>
<p><span class="math display">\[
\begin{aligned}
W + o_p(1) &amp; = -2 \log(\mathcal{L}_{0} / \mathcal{L}_{1}) \text{, so that} \\
\exp(-0.5 W) + o_p(1) &amp; = \mathcal{L}_{0} / \mathcal{L}_{1}.
\end{aligned}
\]</span></p>
<p><a href="#eq-w-p" class="quarto-xref">Equation&nbsp;2</a> shows that the Wald statistic <span class="math inline">\(W\)</span> can be calculated from it’s corresponding <span class="math inline">\(p\)</span>-value. However, the <span class="math inline">\(p\)</span>-values shown in <a href="#fig-jab-jzs" class="quarto-xref">Figure&nbsp;2</a> based on <span class="math inline">\(t\)</span>-values with varying degrees of freedom. When we use these <span class="math inline">\(p\)</span>-values to calculate JAB, we deviate from the original derivation of JAB in two ways: (1) The underlying <span class="math inline">\(t\)</span>-statistic is based on a standard error that relies on the unbiased estimate of the population variance (Bessel’s correction, <span class="math inline">\(n - 1\)</span>). The Wald statistic, however, is based on the uncorrected maximum likelihood estimate of the variance. (2) The <span class="math inline">\(p\)</span>-value is based on the <span class="math inline">\(t\)</span>-distribution rather than the standard normal distribution. <a href="#fig-jabp-jzs" class="quarto-xref">Figure&nbsp;6</a> illustrates the consequences of these deviations. JAB overstates the evidence for <span class="math inline">\(\mathcal{H}_1\)</span> when <span class="math inline">\(n_\text{eff}\)</span> is small. Note, however, that in the data used here the bias exceedes a factor of 3 only in very small samples. We thus believe, in most situations, the <span class="math inline">\(p\)</span>-based JAB is a fair approximation to the JZS-Bayes factor for <span class="math inline">\(t\)</span>-tests. To quote Jeffreys (1961), another influential Bayesian statistician, on the precision of Bayes factors:</p>
<blockquote class="blockquote">
<p>it will seldom matter appreciably to further procedure if [the Bayes factor] is wrong by as much as a factor of 3. (p.&nbsp;433)</p>
</blockquote>
<div class="cell">
<div class="cell-output-display">
<div id="fig-jabp-jzs" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-jabp-jzs-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="whats-in-a-p-value_files/figure-html/fig-jabp-jzs-1.png" class="img-fluid figure-img" width="739">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-jabp-jzs-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Linear relationships between analytic JZS-Bayes factors for point null hypotheses and <span class="math inline">\(p\)</span>-value-based JAB for 704 <span class="math inline">\(t\)</span>-test results collected by Aczel et al.&nbsp;(2018) and Wetzels et al.&nbsp;(2011). Triangles represent the logarithm of the one-sided <span class="math inline">\(p\)</span>-values, circles represent the logarithm of <span class="math inline">\(\text{JAB}_{01}\)</span>. The color of points indicates the effective sample size. The thick solid black line shows the estimated linear relationship between the one-sided <span class="math inline">\(p\)</span> values and the JZS-Bayes factor. The grey area shows the margin of error of a factor of 3 (p.&nbsp;433, Jeffreys, 1961).
</figcaption>
</figure>
</div>
</div>
</div>
<p>The results shown in <a href="#fig-jabp-jzs" class="quarto-xref">Figure&nbsp;6</a> rely on the exact likelihood ratio, which can be calculated from the <span class="math inline">\(t\)</span>-value [Kendall &amp; Stuart, 1961; <span class="citation" data-cites="Murtaugh2014">Murtaugh (<a href="#ref-Murtaugh2014" role="doc-biblioref">2014</a>)</span>; <span class="citation" data-cites="Francis2022">Francis and Jakicic (<a href="#ref-Francis2022" role="doc-biblioref">2022</a>)</span>; <span class="citation" data-cites="Francis2016">Francis (<a href="#ref-Francis2016" role="doc-biblioref">2016</a>)</span>],</p>
<p><span class="math display">\[
\log(\mathcal{L}_{1} / \mathcal{L}_{0}) = \frac{N}{2}\log\bigg(1 + \frac{t^2}{N - k}\bigg),
\]</span></p>
<p>where <span class="math inline">\(N\)</span> is the total sample size and <span class="math inline">\(k\)</span> is the number of samples. The term <span class="math inline">\(N - k\)</span> represents the residual degrees of freedom, which serve as Bessel’s correction for the unbiased estimate of the population variance. As noted above, this is necessary because the likelihood ratio is based on the uncorrected maximum likelihood estimate of the variance. We have found that the likelihood ratio approximation based on <span class="math inline">\(p\)</span> can yield even better results if the approximate <span class="math inline">\(W\)</span> is adjusted by a corrective factor of <span class="math inline">\((N / (N - k))\)</span>, where <span class="math inline">\(N\)</span> is the total sample size and <span class="math inline">\(k\)</span> is the number of samples:</p>
<p><span class="math display">\[
\begin{aligned}
W_t &amp; = \left[Q_{\mathcal{N(0,1)}}(p_t/2)\right]^2 \\
   &amp; \approx \frac{(\hat \theta - \theta_0)^2}{\sum{(\theta_i - \theta_0)^2} / [(N - k) \; n_\text{eff}]} \\ \\
W &amp; \approx W_t \frac{N}{N - k} \\
  &amp; \approx \frac{(\hat \theta - \theta_0)^2}{\sum{(\theta_i - \theta_0)^2} / [N \; n_\text{eff}]},
\end{aligned}
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\text{JAB}_{01} \approx A \; \sqrt{n_\text{eff}} \; \exp\left(-0.5 W_t\right)^{N/(N - k)}.
\]</span></p>
<p>The correction yields a <span class="math inline">\(t\)</span> statistic calculated from the maximum likelihood estimate of the variance. This statistic is known to follow a location-scale <span class="math inline">\(t\)</span> distribution with <span class="math inline">\(t(\mu = 0, \tau^2 = N / (N - k), \nu = N - k)\)</span>. Knowing that <span class="math inline">\(t(\nu = n - 1) \xrightarrow[]{D} \mathcal{N}(\mu = 0, \sigma^2 = 1)\)</span> as <span class="math inline">\(n \to \infty\)</span>, we see that the location-scale <span class="math inline">\(t\)</span> distribution, too, converges to the standard normal distribution as the sample size increases. <a href="#fig-bf-t-z" class="quarto-xref">Figure&nbsp;7</a> shows the bias in JAB for a one-sample <span class="math inline">\(t\)</span>-test when <span class="math inline">\(W\)</span> approximated from <span class="math inline">\(p\)</span>, with and without the correction, relative to the analytic likelihood ratio. Both approximations work well even in relatively small samples—<span class="math inline">\(n &gt; 10\)</span> and <span class="math inline">\(n &gt; 5\)</span>, respectively—and in particular for <span class="math inline">\(p &gt; .05\)</span>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-bf-t-z" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bf-t-z-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="whats-in-a-p-value_files/figure-html/fig-bf-t-z-1.png" class="img-fluid figure-img" width="528">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bf-t-z-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: Bias of likelihood ratio approximations from <span class="math inline">\(p\)</span> of a one-sample <span class="math inline">\(t\)</span>-test (<span class="math inline">\(W_t\)</span>; left panel) and with additional correction (<span class="math inline">\(N / (N - 1)\)</span>; right panel). The grey area shows the margin of error of a factor of 3 (p.&nbsp;433, Jeffreys, 1961).
</figcaption>
</figure>
</div>
</div>
</div>
<p>When used to calculate JAB, the corrective factor should also be applied to the standard error,</p>
<p><span class="math display">\[
\text{SE}(\hat \theta) \approx \sqrt{[\text{SE}_t(\hat \theta)]^2 \frac{N}{N - k}}.
\]</span></p>
<!-- Wagenmakers (2021, pp. 19--20) points out that the Bayes factors assuming a unit-information prior and a JZS-prior asymptotically approach a constant ratio of $0.5~\sqrt{\pi}$.
Applying this asymptotic correction to JAB yields an even closes approximation of the JZS-Bayes factor. -->
<!-- 
## Comparison of $3 p \sqrt{n}$-rule to $\text{BIC}$ {.appendix #sec-appendix-bic}


The [3pn rule](3pn-rule.md) is an approximation to an approximate Bayes factor.
The BIC is a similar, widely used approximation that is not limited to testing a single parameter.
Both assume a [unit-information-prior](unit-information-prior.md) [[@wagenmakers2021]].
To compare them, we can convert $t$ (or $p$) and $n$ to the likelihood ratio and the $\text{BIC}$.

We can use the likelihood ratio to calculate the BIC difference using the effective sample size $n_\text{eff}$,

$$
\Delta\text{BIC} = 2 \log(\mathcal{L}_{1}) - \log(\mathcal{L}_{0}) - k \log(n_\text{eff}),
$$

where $k$ is the number of parameters in the model. For the $t$-tests, $k = 1$.
We can then transform the BIC to the Bayes factor according to the formula $\text{BF}_{01} = \exp(\Delta\text{BIC}/2)$.
@fig-3pn-bic-ttest shows the close relationship between JAB and the BIC-Bayes factor for the $t$-tests.
Discrepencies occur only for very small effective sample sizes, where the BIC-Bayes factor indicates stronger evidence for the alternative hypothesis.



**BIC uses a slightly different unit-information prior, i.e., centered on $\hat\theta$ (e.g., https://doi.org/10.1177/0049124103262065).**

A comparison between JAB and BIC must adjust the effective sample size in the calculation of the standard error of the wald statistic (Eq. 5, Wagenmakers, 2021) or, equivalently, in the likelihood of the BIC to obtain the same prior centered on 0.




::: {.cell}
::: {.cell-output-display}
![Linear relationships between BIC approximation to the Bayes factors (**???**) for point null hypotheses and the $3p\sqrt{n}$-approximation for 704 $t$-test results collected by Aczel et al. (2018) and Wetzels et al. (2011). Triangles represent the logarithm of the one-sided $p$-values, circles represent the logarithm of $3 p \sqrt{n}$-JAB. The color of points indicates the effective sample size. The solid black line shows the estimated linear relationship between the one-sided $p$ values and the BIC approximation to the Bayes factor.](whats-in-a-p-value_files/figure-html/fig-3pn-bic-ttest-1.png){#fig-3pn-bic-ttest width=739.2}
:::
:::



The remaining deviations between JAB and BIC are small and the result of assuming a squared $z$-test statistic (in JAB) when it really is a $t$ statistic and the piecewise linear approximation of the $3 p \sqrt{n}$-rule, @fig-bf-t-z.



::: {.cell}
::: {.cell-output-display}
![Bias of JAB and $3p\sqrt{n}$-rule relative to the BIC-BF. Each colored line represents a constant $p \in [.999, .5, .05, .005, .001]$ with the color indicating the magnitude of the BIC-BF.](whats-in-a-p-value_files/figure-html/fig-bf-t-z2-1.png){#fig-bf-t-z2 width=672}
:::
:::





Similarly, we can calculate the BIC for Pearson's $\chi^2$-test and the logistic regression analysis,

$$
\log(\mathcal{L}_{1}) - \log(\mathcal{L}_{0}) = -0.5 \chi^2(1) = -0.5 z^2.
$$

@fig-3pn-bic-prop shows the close relationship between the $3 p \sqrt{n}$-rule and the BIC-Bayes factors.
Even for very small effective sample sizes the two approximations are very similar.


#| label: fig-3pn-bic-prop
#| fig-cap: !expr glue::glue("Linear relationships between BIC approximation to the Bayes factors (**???**) and $p$-value-based approximations for <<nrow(hoekstra)>> results of tests comparing two proportions collected by Hoekstra et al. (2018; reanalyzed by Dablander et al., 2021). The top panel shows the results of Pearson's $\\chi^2$-test; the bottom panel shows the results of the logistic regression analysis. Triangles represent the logarithm of the one-sided $p$-values, circles represent the logarithm of $3 p \\sqrt{n}$-JAB. The color of points indicates the effective sample size.", .open = "<<", .close = ">>")
#| fig-height: 7
#| fig-width: 7

ib_plot <- ggplot(hoekstra) +
  aes(y = bicbf_prop) +
  geom_abline(slope = 1, intercept = 0, linetype = "22") +
  geom_point(aes(x = jabp_prop, shape = "JAB", fill = n_prop), color = "white", size = 3) +
  geom_point(aes(x = prop_test$p.value/2, shape = "p", fill = n_prop), color = "white", size = 3) +
  # scale_shape_manual(values = c(21, 24), labels = c(bquote(3*italic(p)*sqrt(italic(n))*"-JAB"["01"]), bquote("One-sided"~italic(p))), name = "Approximation", guide = guide_legend(override.aes = list(fill = "black", size = 4), reverse = TRUE, direction = "horizontal", title.position = "top", title.hjust = 0.5, order = 1)) +
  # scale_fill_viridis_c(option = "F", begin = 0.3, end = 0.8, direction = -1, trans = "log", breaks = c(3, 7, 20, 50, 150), name = "n", guide = guide_colorbar(title.position = "top", title.hjust = 0.5)) +
  # scale_x_continuous(
  #   trans = "log"
  #   , breaks = bf_breaks
  #   , labels = bf_labels
  # ) +
  # scale_y_continuous(
  #   trans = "log"
  #   , breaks = bf_breaks
  #   , labels = bf_labels
  # ) +
  # coord_fixed(ratio = 1) +
  ggtitle(bquote(2%*%2*"-"*Chi^2*"-test")) +
  labs(x = NULL, y = bquote("BIC-"*BF["01"])) +
  papaja::theme_apa(base_size = 16, box = TRUE) +
  # theme(
  #   axis.text.x = element_text(angle = 45, hjust = 1)
  #   , legend.box = "horizontal"
  # )
  NULL

lt_plot <- ggplot(hoekstra) +
  aes(y = bicbf_logit) +
  geom_abline(slope = 1, intercept = 0, linetype = "22") +
  geom_point(aes(x = jabp_logit, shape = "JAB", fill = n_logit), color = "white", size = 3) +
  geom_point(aes(x = logit_glm$p.value/2, shape = "p", fill = n_logit), color = "white", size = 3) +
  # scale_shape_manual(values = c(21, 24), labels = c(bquote(3*italic(p)*sqrt(italic(n))*"-JAB"["01"]), bquote("One-sided"~italic(p))), name = "Approximation", guide = guide_legend(override.aes = list(fill = "black", size = 4), reverse = TRUE, direction = "horizontal", title.position = "top", title.hjust = 0.5, order = 1)) +
  # scale_fill_viridis_c(option = "F", begin = 0.3, end = 0.8, direction = -1, trans = "log", breaks = c(3, 7, 20, 50, 150), name = "n", guide = guide_colorbar(title.position = "top", title.hjust = 0.5)) +
  # scale_x_continuous(
  #   trans = "log"
  #   , breaks = bf_breaks
  #   , labels = bf_labels
  # ) +
  # scale_y_continuous(
  #   trans = "log"
  #   , breaks = bf_breaks
  #   , labels = bf_labels
  # ) +
  # coord_fixed(ratio = 1) +
  ggtitle("Logistic regression") +
  labs(x = "Approximation", y = bquote("BIC-"*BF["01"])) +
  papaja::theme_apa(base_size = 16, box = TRUE) +
  # theme(
  #   axis.text.x = element_text(angle = 45, hjust = 1)
  #   , legend.box = "horizontal"
  # )
  NULL

plot_layout <- "
AC
BC
"

free(ib_plot, type = "label") + free(lt_plot, type = "label") + guide_area() +
  plot_layout(
    design = plot_layout
    , guides = "collect"
    , axes = "collect"
  ) & 
  scale_shape_manual(values = c(21, 24), labels = c(bquote(3*italic(p)*sqrt(italic(n))*"-JAB"["01"]), bquote("One-sided"~italic(p))), name = "Approximation", guide = guide_legend(override.aes = list(fill = "black", size = 4), reverse = TRUE, direction = "vertical", title.position = "top", title.hjust = 0.5, order = 1)) &
  scale_fill_viridis_c(option = "F", begin = 0.3, end = 0.8, direction = -1, trans = "log", breaks = c(3, 10, 100, 1000, 10000), name = "n", guide = guide_colorbar(title.position = "top", title.hjust = 0.5, direction = "vertical"), limits = range(c(hoekstra$n_prop, hoekstra$n_logit), order = 2)) &
  # guides( 
  #   shape = guide_legend(order = 1),
  #   fill = guide_colorbar(color = 2)
  # ) &
  scale_x_continuous(
    trans = "log"
    , breaks = bf_breaks
    , labels = bf_labels
    , limits = range(
      c(unlist(hoekstra[, c("jabp_logit", "jabp_prop")])
      , hoekstra$logit_glm$p.value/2
      , hoekstra$prop_test$p.value/2)
    )
  ) &
  scale_y_continuous(
    trans = "log"
    , breaks = bf_breaks
    , labels = bf_labels
    , limits = range(hoekstra[, c("bicbf_logit", "bicbf_prop")])
  ) &
  coord_fixed(ratio = 1) &
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
    , title = element_text(size = rel(1/1.2))
  )
``` -->

</div></section><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Albarracn2024" class="csl-entry" role="listitem">
Albarracín, Dolores, Bita Fayaz-Farkhad, and Javier A. Granados Samayoa. 2024. <span>“Determinants of Behaviour and Their Efficacy as Targets of Behavioural Change Interventions.”</span> <em>Nature Reviews Psychology</em> 3 (6): 377–92. <a href="https://doi.org/10.1038/s44159-024-00305-0">https://doi.org/10.1038/s44159-024-00305-0</a>.
</div>
<div id="ref-Allabadi2024" class="csl-entry" role="listitem">
Al-Labadi, Luai, Ayman Alzaatreh, and Michael Evans. 2024. <span>“How to Measure Evidence and Its Strength: Bayes Factors or Relative Belief Ratios?”</span> <a href="https://doi.org/10.48550/arXiv.2301.08994">https://doi.org/10.48550/arXiv.2301.08994</a>.
</div>
<div id="ref-Bartos2024" class="csl-entry" role="listitem">
Bartoš, František, Alexandra Sarafoglou, Henrik R. Godmann, Amir Sahrani, David Klein Leunk, Pierre Y. Gui, David Voss, et al. 2024. <span>“Fair Coins Tend to Land on the Same Side They Started: Evidence from 350,757 Flips.”</span> <a href="https://doi.org/10.48550/ARXIV.2310.04153">https://doi.org/10.48550/ARXIV.2310.04153</a>.
</div>
<div id="ref-Beal1987" class="csl-entry" role="listitem">
Beal, S. L. 1987. <span>“Asymptotic Confidence Intervals for the Difference Between Two Binomial Parameters for Use with Small Samples.”</span> <em>Biometrics</em> 43 (4): 941. <a href="https://doi.org/10.2307/2531547">https://doi.org/10.2307/2531547</a>.
</div>
<div id="ref-Berger2013" class="csl-entry" role="listitem">
Berger, James O., M. J. Bayarri, and L. R. Pericchi. 2013. <span>“The Effective Sample Size.”</span> <em>Econometric Reviews</em> 33 (1–4): 197–217. <a href="https://doi.org/10.1080/07474938.2013.807157">https://doi.org/10.1080/07474938.2013.807157</a>.
</div>
<div id="ref-Berger1987" class="csl-entry" role="listitem">
Berger, James O., and Thomas Sellke. 1987. <span>“Testing a Point Null Hypothesis: The Irreconcilability ofP-Values and Evidence.”</span> <em>Journal of the American Statistical Association</em> 82 (397): 112–22. <a href="https://doi.org/10.1080/01621459.1987.10478397">https://doi.org/10.1080/01621459.1987.10478397</a>.
</div>
<div id="ref-Cohen1994" class="csl-entry" role="listitem">
Cohen, Jacob. 1994. <span>“The Earth Is Round (p &lt; .05).”</span> <em>American Psychologist</em> 49 (12): 997–1003. <a href="https://doi.org/10.1037/0003-066x.49.12.997">https://doi.org/10.1037/0003-066x.49.12.997</a>.
</div>
<div id="ref-Cole2020" class="csl-entry" role="listitem">
Cole, Stephen R, Jessie K Edwards, and Sander Greenland. 2020. <span>“Surprise!”</span> <em>American Journal of Epidemiology</em> 190 (2): 191–93. <a href="https://doi.org/10.1093/aje/kwaa136">https://doi.org/10.1093/aje/kwaa136</a>.
</div>
<div id="ref-Cox2011" class="csl-entry" role="listitem">
Cox, D. R., and Christl A. Donnelly. 2011. <em>Principles of Applied Statistics</em>. Cambridge University Press. <a href="https://doi.org/10.1017/cbo9781139005036">https://doi.org/10.1017/cbo9781139005036</a>.
</div>
<div id="ref-Edwards1963" class="csl-entry" role="listitem">
Edwards, Ward, Harold Lindman, and Leonard J. Savage. 1963. <span>“Bayesian Statistical Inference for Psychological Research.”</span> <em>Psychological Review</em> 70 (3): 193–242. <a href="https://doi.org/10.1037/h0044139">https://doi.org/10.1037/h0044139</a>.
</div>
<div id="ref-Etz2017" class="csl-entry" role="listitem">
Etz, Alexander, Quentin F. Gronau, Fabian Dablander, Peter A. Edelsbrunner, and Beth Baribault. 2017. <span>“How to Become a Bayesian in Eight Easy Steps: An Annotated Reading List.”</span> <em>Psychonomic Bulletin &amp;Amp; Review</em> 25 (1): 219–34. <a href="https://doi.org/10.3758/s13423-017-1317-5">https://doi.org/10.3758/s13423-017-1317-5</a>.
</div>
<div id="ref-Francis2016" class="csl-entry" role="listitem">
Francis, Gregory. 2016. <span>“Equivalent Statistics and Data Interpretation.”</span> <em>Behavior Research Methods</em> 49 (4): 1524–38. <a href="https://doi.org/10.3758/s13428-016-0812-3">https://doi.org/10.3758/s13428-016-0812-3</a>.
</div>
<div id="ref-Francis2022" class="csl-entry" role="listitem">
Francis, Gregory, and Victoria Jakicic. 2022. <span>“Equivalent Statistics for a One-Sample t-Test.”</span> <em>Behavior Research Methods</em> 55 (1): 77–84. <a href="https://doi.org/10.3758/s13428-021-01775-3">https://doi.org/10.3758/s13428-021-01775-3</a>.
</div>
<div id="ref-Gigerenzer2018" class="csl-entry" role="listitem">
Gigerenzer, Gerd. 2018. <span>“Statistical Rituals: The Replication Delusion and How We Got There.”</span> <em>Advances in Methods and Practices in Psychological Science</em> 1 (2): 198–218. <a href="https://doi.org/10.1177/2515245918771329">https://doi.org/10.1177/2515245918771329</a>.
</div>
<div id="ref-Greenland2019" class="csl-entry" role="listitem">
Greenland, Sander. 2019. <span>“Valid p-Values Behave Exactly as They Should: Some Misleading Criticisms of p-Values and Their Resolution with s-Values.”</span> <em>The American Statistician</em> 73 (sup1): 106–14. <a href="https://doi.org/10.1080/00031305.2018.1529625">https://doi.org/10.1080/00031305.2018.1529625</a>.
</div>
<div id="ref-Held2018" class="csl-entry" role="listitem">
Held, Leonhard, and Manuela Ott. 2018. <span>“On p-Values and Bayes Factors.”</span> <em>Annual Review of Statistics and Its Application</em> 5 (1): 393–419. <a href="https://doi.org/10.1146/annurev-statistics-031017-100307">https://doi.org/10.1146/annurev-statistics-031017-100307</a>.
</div>
<div id="ref-Hubbard2008" class="csl-entry" role="listitem">
Hubbard, Raymond, and R. Murray Lindsay. 2008. <span>“Why p Values Are Not a Useful Measure of Evidence in Statistical Significance Testing.”</span> <em>Theory &amp;Amp; Psychology</em> 18 (1): 69–88. <a href="https://doi.org/10.1177/0959354307086923">https://doi.org/10.1177/0959354307086923</a>.
</div>
<div id="ref-Kruschke2014" class="csl-entry" role="listitem">
Kruschke, John. 2014. <em>Doing Bayesian Data Analysis - a Tutorial with r, JAGS, and Stan</em>. Amsterdam, Boston: Academic Press.
</div>
<div id="ref-Lakens2022" class="csl-entry" role="listitem">
Lakens, Daniël. 2022. <em>Improving Your Statistical Inferences</em>. Zenodo. <a href="https://doi.org/10.5281/ZENODO.6409077">https://doi.org/10.5281/ZENODO.6409077</a>.
</div>
<div id="ref-Marsman2016" class="csl-entry" role="listitem">
Marsman, Maarten, and Eric-Jan Wagenmakers. 2016. <span>“Three Insights from a Bayesian Interpretation of the One-Sided p Value.”</span> <em>Educational and Psychological Measurement</em> 77 (3): 529–39. <a href="https://doi.org/10.1177/0013164416669201">https://doi.org/10.1177/0013164416669201</a>.
</div>
<div id="ref-Morey2016" class="csl-entry" role="listitem">
Morey, Richard D., Jan-Willem Romeijn, and Jeffrey N. Rouder. 2016. <span>“The Philosophy of Bayes Factors and the Quantification of Statistical Evidence.”</span> <em>Journal of Mathematical Psychology</em> 72 (June): 6–18. <a href="https://doi.org/10.1016/j.jmp.2015.11.001">https://doi.org/10.1016/j.jmp.2015.11.001</a>.
</div>
<div id="ref-Murtaugh2014" class="csl-entry" role="listitem">
Murtaugh, Paul A. 2014. <span>“In Defense of p Values.”</span> <em>Ecology</em> 95 (3): 611–17. <a href="https://doi.org/10.1890/13-0590.1">https://doi.org/10.1890/13-0590.1</a>.
</div>
<div id="ref-Perezgonzalez2015" class="csl-entry" role="listitem">
Perezgonzalez, Jose D. 2015. <span>“P-Values as Percentiles. Commentary on: "Null Hypothesis Significance Tests. A Mix-up of Two Different Theories: The Basis for Widespread Confusion and Numerous Misinterpretations".”</span> <em>Frontiers in Psychology</em> 6 (April). <a href="https://doi.org/10.3389/fpsyg.2015.00341">https://doi.org/10.3389/fpsyg.2015.00341</a>.
</div>
<div id="ref-Rafi2020" class="csl-entry" role="listitem">
Rafi, Zad, and Sander Greenland. 2020. <span>“Semantic and Cognitive Tools to Aid Statistical Science: Replace Confidence and Significance by Compatibility and Surprise.”</span> <em>BMC Medical Research Methodology</em> 20 (1). <a href="https://doi.org/10.1186/s12874-020-01105-9">https://doi.org/10.1186/s12874-020-01105-9</a>.
</div>
<div id="ref-Wagenmakers2022" class="csl-entry" role="listitem">
Wagenmakers, Eric-Jan. 2022. <span>“Approximate Objective Bayes Factors from p-Values and Sample Size: The 3p√n Rule,”</span> January. <a href="https://doi.org/10.31234/osf.io/egydq">https://doi.org/10.31234/osf.io/egydq</a>.
</div>
<div id="ref-Wasserman2000" class="csl-entry" role="listitem">
Wasserman, Larry. 2000. <span>“Bayesian Model Selection and Model Averaging.”</span> <em>Journal of Mathematical Psychology</em> 44 (1): 92–107. <a href="https://doi.org/10.1006/jmps.1999.1278">https://doi.org/10.1006/jmps.1999.1278</a>.
</div>
<div id="ref-Wilks1938" class="csl-entry" role="listitem">
Wilks, S. S. 1938. <span>“The Large-Sample Distribution of the Likelihood Ratio for Testing Composite Hypotheses.”</span> <em>The Annals of Mathematical Statistics</em> 9 (1): 60–62. <a href="https://doi.org/10.1214/aoms/1177732360">https://doi.org/10.1214/aoms/1177732360</a>.
</div>
<div id="ref-Wood2024" class="csl-entry" role="listitem">
Wood, Wendy. 2024. <span>“Habits, Goals, and Effective Behavior Change.”</span> <em>Current Directions in Psychological Science</em> 33 (4): 226–32. <a href="https://doi.org/10.1177/09637214241246480">https://doi.org/10.1177/09637214241246480</a>.
</div>
</div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>